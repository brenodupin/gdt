<div align="center">
  <img src="img/gdt_no_background.png" width="50%">

$${\color{#E0AF68}{\LARGE\textsf{ðŸ§¬ Standardizing gene names across organelle genomes ðŸ§¬}}}$$
![Build Status](https://img.shields.io/badge/tests-in_development-yellow)
[![Checked with mypy](https://www.mypy-lang.org/static/mypy_badge.svg)](https://mypy-lang.org/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Linting: Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/charliermarsh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)
[![License](https://img.shields.io/badge/license-MIT-purple)](https://github.com/brenodupin/gdt/blob/master/LICENSE)
[![DOI:10.1101/2025.06.15.659783v1](https://img.shields.io/badge/biorxiv-10.1101/2025.06.15.659783-blue)](https://doi.org/10.1101/2025.06.15.659783)

</div>

# Table of Contents
place_holder

## Overview

GDT (Gene Dictonary Tool) is a protocol for the creation and implementation of a gene dictionary across any type of annotated genomes. This Python library offers a suite of functionalities that enables the manipulation and integration of .gdt files into other pipelines seamlessly.

## Getting Started

### Requirements

- [Python](https://www.python.org/) `(>=3.10)`
- [pandas](https://pandas.pydata.org/) `(>=1.5.3,<3.0.0)`

> [!NOTE]  
> [biopython](https://biopython.org) is necessary for `AN_missing_gene_dict.ipynb`, and can be installed `with pip install biopython`

### Installation
You can install the library with pip:
```
pip install gdt
```

If you plan on running `AN_missing_gene_dict.ipynb`, you need to install [biopython](https://biopython.org)
```
pip install biopython
```

### CLI commands
`



work in progress
```
â”œâ”€â”€ CITATION.cff       <- Contains metadata on how the project might eventually be published. 
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile           <- Makefile with commands like `make data` or `make train`
â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
â”œâ”€â”€ config             <- Configuration options for the analysis. 
|   â”œâ”€â”€ config.yaml    <- Snakemake config file. 
|   â””â”€â”€ samples.tsv    <- A metadata table for all the samples run in the analysis.  
â”‚
â”œâ”€â”€ docs               <- A default Sphinx project; see sphinx-doc.org for details
â”‚
â”œâ”€â”€ environment.yaml   <- The requirements file for reproducing the analysis environment, e.g.
â”‚                         generated with `conda env export > environment.yaml`
â”‚
â”œâ”€â”€ img                <- A place to store images associated with the project/pipeline, e.g. a 
â”‚                         a figure of the pipeline DAG. 
â”‚
â”œâ”€â”€ notebooks          <- Jupyter or Rmd notebooks. Naming convention is a number (for ordering),
â”‚                         the creator's initials, and a short `-` delimited description, e.g.
â”‚                         `1.0-jqp-initial-data-exploration`.
â”‚
â”œâ”€â”€ references         <- Data dictionaries, manuals, and all other explanatory materials.
â”‚
â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
â”‚   â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
â”‚
â”œâ”€â”€ resources          <- Place for data. By default excluded from the git repository. 
â”‚   â”œâ”€â”€ external       <- Data from third party sources.
â”‚   â””â”€â”€ raw_data       <- The original, immutable data dump.
â”‚
â”œâ”€â”€ results            <- Final output of the data processing pipeline. By default excluded from the git repository.
â”‚ 
â”œâ”€â”€ sandbox            <- A place to test scripts and ideas. By default excluded from the git repository.
â”‚ 
â”œâ”€â”€ scripts            <- A place for short shell or python scripts.
â”‚ 
â”œâ”€â”€ setup.py           <- Makes project pip installable (pip install -e .) so src can be importe
â”‚
â”œâ”€â”€ src                <- Source code for use in this project.
â”‚   â”œâ”€â”€ __init__.py    <- Makes src a Python module
â”œâ”€â”€ tox.ini            <- tox file with settings for running tox; see tox.readthedocs.io
â”‚
â”œâ”€â”€ workflow           <- Place to store the main pipeline for rerunning all the analysis. 
â”‚   â”œâ”€â”€ envs           <- Contains different conda environments in .yaml format for running the pipeline. 
â”‚   â”œâ”€â”€ rules          <- Contains .smk files that are included by the main Snakefile, including common.smk for functions. 
â”‚   â”œâ”€â”€ scripts        <- Contains different R or python scripts used by the script: directive in Snakemake.
â”‚   â”œâ”€â”€ Snakefile      <- Contains the main entrypoint to the pipeline.
â”‚ 
â”œâ”€â”€ workspace          <- Space for intermediate results in the pipeline. By default excluded from the git repository.  
```

<p><small>Project inspired by the <a target="_blank" href="https://drivendata.github.io/cookiecutter-data-science/">cookiecutter data science project template</a>
