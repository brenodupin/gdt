{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df68e5f6",
   "metadata": {},
   "source": [
    "### Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9664aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and functions\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import gdt\n",
    "\n",
    "RE_ID = re.compile(r\"ID=([^;]+)\")\n",
    "RE_parent = re.compile(r\"Parent=([^;]+)\")\n",
    "\n",
    "# Regex patterns for extracting GFF attributes\n",
    "RE_gene = re.compile(r\"gene=([^;]+)\")\n",
    "RE_product = re.compile(r\"product=([^;]+)\")\n",
    "RE_description = re.compile(r\"description=([^;]+)\")\n",
    "RE_name = re.compile(r\"Name=([^;]+)\")\n",
    "RE_note = re.compile(r\"Note=([^;]+)\")\n",
    "RE_gene_synonym = re.compile(r\"gene_synonym=([^;]+)\")\n",
    "\n",
    "# Features to extract from GFF files (must match the regex names above without RE_ prefix)\n",
    "# ORDER MATTERS: Listed from most descriptive/best for identification to least descriptive\n",
    "# This order determines the priority for filling the feature_name column - earlier entries take precedence\n",
    "features_order = [\"gene\", \"product\", \"description\", \"name\", \"note\", \"gene_synonym\"]\n",
    "\n",
    "# To add a new feature for extraction:\n",
    "# 1. Create a regex pattern with the naming convention: RE_{feature_name}\n",
    "#    Use any regex pattern that captures the desired value from GFF files.\n",
    "#    Common pattern: RE_{feature_name} = re.compile(r\"{attribute_name}=([^;]+)\")\n",
    "#    but you can customize the regex to capture exactly what you need.\n",
    "#\n",
    "# 2. Add the feature name (without RE_ prefix) to the features_name list\n",
    "#    IMPORTANT: Place it in the appropriate position based on how descriptive/useful\n",
    "#    it is for identification. More descriptive features should come first in the list.\n",
    "#\n",
    "# Example - to extract 'locus_tag' attributes:\n",
    "# RE_locus_tag = re.compile(r\"locus_tag=([^;]+)\")  # or any custom regex\n",
    "# features_name = [\"locus_tag\", \"gene\", \"product\", \"description\", \"name\", \"note\", \"gene_synonym\"]  # if locus_tag is most descriptive\n",
    "# # OR\n",
    "# features_name = [\"gene\", \"product\", \"description\", \"locus_tag\", \"name\", \"note\", \"gene_synonym\"]  # if locus_tag is moderately descriptive\n",
    "# # OR\n",
    "# features_name = [\"gene\", \"product\", \"description\", \"name\", \"note\", \"gene_synonym\", \"locus_tag\"] # if locus_tag is least descriptive\n",
    "#\n",
    "# CRITICAL: The regex variable name (after RE_) must exactly match the name\n",
    "# you add to features_name for the extraction to work properly\n",
    "\n",
    "re_features = {}\n",
    "for name in features_order:\n",
    "    try:\n",
    "        re_features[name] = globals()[f\"RE_{name}\"]\n",
    "    except KeyError:\n",
    "        print(f\"Warning: No regex found for '{name}' (expected variable: RE_{name})\")\n",
    "\n",
    "\n",
    "def increment_gdict_file(path):\n",
    "    \"\"\"Increment the GDICT file name by 1.\n",
    "\n",
    "    Example: fungi-ncbi_pilot_03.gdict -> fungi-ncbi_pilot_04.gdict\n",
    "    \"\"\"\n",
    "    plist = path.stem.split(\"_\")\n",
    "    if plist[-1] == \"stripped\":\n",
    "        plist[-1] = \"pilot\"\n",
    "        plist.append(0)\n",
    "\n",
    "    try:\n",
    "        number = int(plist[-1]) + 1\n",
    "        plist[-1] = f\"{number:02d}\"\n",
    "    except ValueError:\n",
    "        raise ValueError(\n",
    "            f\"Invalid GDICT file name: {path.name}. Expected format: <preferred_name>_##.gdict, where ## is a number.\"\n",
    "        )\n",
    "    return path.parent / f'{\"_\".join(plist)}{path.suffix}', number\n",
    "\n",
    "\n",
    "def most_recent_gdict(dir_path, prefix):\n",
    "    \"\"\"Get the most recent gdict file in the directory.\n",
    "\n",
    "    Arguments:\n",
    "        dir_path (Path): Directory to search for GDICT files.\n",
    "        prefix (str): Prefix of the GDICT files to search for. It will match files like \"*<prefix>*.gdict\".\n",
    "\n",
    "    Returns:\n",
    "        Path: Path to the most recent GDICT file.\n",
    "\n",
    "    \"\"\"\n",
    "    temp_files = list(\n",
    "        dir_path.glob(f\"*{prefix}*.gdict\")\n",
    "    )  # maybe change to check for numbers after prefix?\n",
    "    if not temp_files:\n",
    "        return dir_path / f\"{prefix}_00.gdict\"\n",
    "    return gdt.natural_sort(temp_files, key=lambda x: x.stem)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b64165",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5694138",
   "metadata": {},
   "source": [
    "#### A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines all the global variables used in the script.\n",
    "# Change these variables to match your local setup.\n",
    "# The most_recent_gdt_file variable should be set to the path of the most recent GDT file,\n",
    "# OR the stripped GDT file used in filter command, if applicable.\n",
    "\n",
    "DATA_DIR = \"/home/msanital/Desktop/gdt/sandbox/STAR_example/metazoans_mit\"\n",
    "newest_gdict_file = \"metazoans_mit_pilot_04.gdict\"\n",
    "global_query_string = gdt.QS_GENE_TRNA_RRNA\n",
    "remove_orfs = True\n",
    "in_folder = True\n",
    "gct = \"MIT\"\n",
    "gff_ext = \".gff3\"\n",
    "gff_suffix = \"\"\n",
    "\n",
    "print(f\"Chosen feature query string: '{global_query_string}'\")\n",
    "\n",
    "\n",
    "# just checking\n",
    "DATA_DIR = Path(DATA_DIR).resolve()\n",
    "if not DATA_DIR.is_dir():\n",
    "    raise FileNotFoundError(f\"Path {DATA_DIR} is not a directory.\")\n",
    "\n",
    "MISC_DIR = DATA_DIR / \"misc\"\n",
    "GDT_DIR = MISC_DIR / \"gdt\"\n",
    "GDT_DIR.mkdir(511, True, True)  # 511 = 0o777\n",
    "\n",
    "AN_missing_dbxref_GeneID = MISC_DIR / \"AN_missing_dbxref_GeneID.txt\"\n",
    "\n",
    "if not AN_missing_dbxref_GeneID.is_file():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Missing {AN_missing_dbxref_GeneID}, did you run gdt-cli filter?\"\n",
    "    )\n",
    "\n",
    "if \"newest_gdict_file\" in globals():\n",
    "    gdict_path = GDT_DIR / newest_gdict_file\n",
    "    if not gdict_path.is_file():\n",
    "        print(\n",
    "            f\"Not found {gdict_path.name}, does it exist in misc/gdt?\\nGDICTs in {GDT_DIR}:\"\n",
    "        )\n",
    "        [print(f\" - {f.name}\") for f in sorted(GDT_DIR.glob(\"*.gdict\"))]\n",
    "        raise FileNotFoundError(\n",
    "            f\"Most recent GDICT file {gdict_path.name} does not exist in {GDT_DIR}.\"\n",
    "        )\n",
    "else:\n",
    "    print(\n",
    "        \"Warning: 'newest_gdict_file' variable not set.\\n\\n\"\n",
    "        \"You should have a GDICT file from AN_missing_gene_dict.ipynb:\\n\"\n",
    "        \"• Set the newest_gdict_file variable\\n\"\n",
    "        \"• Re-run this cell\\n\\n\"\n",
    "        \"If you intend to run this without a GDICT file (e.g., because your GFF files \"\n",
    "        \"don't have dbxrefs and AN_missing_gene_dict.ipynb isnt't needed), this warning can be ignored.\"\n",
    "    )\n",
    "    # to simplify the code, a exetution without newest_gdict_file is\n",
    "    # basically the same as with one, but with and empty gdt file\n",
    "    gdict_path = GDT_DIR / \"pilot_00.gdt\"\n",
    "    gdt.create_empty_gdict(gdict_path)\n",
    "\n",
    "if in_folder:\n",
    "    gff_builder = gdt.GFFPathBuilder().use_folder_builder(\n",
    "        DATA_DIR,\n",
    "        gff_suffix,\n",
    "        gff_ext,\n",
    "    )\n",
    "else:\n",
    "    gff_builder = gdt.GFFPathBuilder().use_standard_builder(\n",
    "        DATA_DIR,\n",
    "        gff_suffix,\n",
    "        gff_ext,\n",
    "    )\n",
    "print(f\"Using GFF builder: {gff_builder}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0e4a9a",
   "metadata": {},
   "source": [
    "#### b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddbed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = MISC_DIR / \"01_missing_dbxref_GeneID.log\"\n",
    "\n",
    "log = gdt.create_simple_logger(\n",
    "    print_to_console=True,\n",
    "    console_level=\"INFO\",\n",
    "    save_to_file=True,\n",
    "    file_level=\"TRACE\",\n",
    "    log_file=log_file,\n",
    ")\n",
    "log.info(\"Running from notebook AN_missing_dbxref_GeneID.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d985e87",
   "metadata": {},
   "source": [
    "### Features Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b24d4",
   "metadata": {},
   "source": [
    "#### A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a53d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(AN_missing_dbxref_GeneID, \"r\") as f:\n",
    "    ANs = [line.strip() for line in f.readlines() if line.strip()]\n",
    "log.info(f\"Found {len(ANs)} ANs in {AN_missing_dbxref_GeneID}\")\n",
    "log.trace(f\"ANs: {ANs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b9e5e",
   "metadata": {},
   "source": [
    "#### B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f3d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GDT file (even if empty)\n",
    "gene_dict = gdt.read_gdict(gdict_path, lazy_info=False)\n",
    "log.info(f\"GeneDict loaded from {gdict_path.name}\")\n",
    "log.debug(f\"path: {gdict_path}\")\n",
    "\n",
    "log.info(\"Header:\")\n",
    "for x in gene_dict.header:\n",
    "    log.info(f\"\\t{x}\")\n",
    "\n",
    "log.info(\"GDT Info:\")\n",
    "gdt.log_info(log, gene_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969c885",
   "metadata": {},
   "source": [
    "#### C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "to_drop = [\"source\", \"type\", \"start\", \"end\", \"score\", \"strand\", \"phase\", \"attributes\"]\n",
    "errors = []\n",
    "\n",
    "log.info(\" ---- [Starting 'Features Extraction'] ----\")\n",
    "\n",
    "for AN in ANs:\n",
    "    log.debug(f\"Processing AN: {AN}\")\n",
    "    an_path = gff_builder.build(AN)\n",
    "    df = gdt.load_gff3(\n",
    "        an_path, query_string=global_query_string, usecols=gdt.GFF3_COLUMNS\n",
    "    )\n",
    "    df = gdt.filter_orfs(df) if remove_orfs else df\n",
    "\n",
    "    df[\"gene_id\"] = df[\"attributes\"].str.extract(RE_ID, expand=False)\n",
    "    df = df[~df[\"gene_id\"].isin(gene_dict)]\n",
    "\n",
    "    # Procedually extract features based on the regex patterns defined\n",
    "    for name, pattern in re_features.items():\n",
    "        df[name] = df[\"attributes\"].str.extract(pattern, expand=False)\n",
    "\n",
    "    if df[features_order].isna().all(axis=1).any():\n",
    "        log.error(\n",
    "            f\"{AN} has row(s) with no identifiable atribute, \"\n",
    "            \"for now filling 'gene' column with 'no_identifiable_attribute'\"\n",
    "        )\n",
    "        errors.append((AN, df[df[features_order].isna().all(axis=1)]))\n",
    "        df.loc[df[features_order].isna().all(axis=1), \"gene\"] = (\n",
    "            \"no_identifiable_attribute\"\n",
    "        )\n",
    "\n",
    "    temp_list.extend(df.to_dict(\"records\"))\n",
    "\n",
    "features_info_df = pd.DataFrame(temp_list)\n",
    "features_info_df = features_info_df.drop(columns=to_drop, errors=\"ignore\")\n",
    "\n",
    "drop_cols = [col for col in features_order if features_info_df[col].isna().all()]\n",
    "\n",
    "# Procedurally fill 'best_feature' based on the order of features_name\n",
    "features_info_df[\"best_feature\"] = features_info_df[features_order[0]]\n",
    "for col in features_order[1:]:\n",
    "    features_info_df[\"best_feature\"] = features_info_df[\"best_feature\"].fillna(\n",
    "        features_info_df[col]\n",
    "    )\n",
    "\n",
    "features_info_df = features_info_df.drop(columns=drop_cols)\n",
    "features_info_df = features_info_df.sort_values(by=\"best_feature\")\n",
    "log.debug(f\"Features info df, writing to {MISC_DIR / 'features_info.tsv'}\")\n",
    "features_info_df.to_csv(MISC_DIR / \"features_info.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "if errors:\n",
    "    log.warning(f\"Errors found in {len(errors)} ANs,\")\n",
    "    for an, df in errors:\n",
    "        log.warning(f\"AN {an} has {len(df)} row(s) with no identifiable attribute.\")\n",
    "        # remove columns that are all nan\n",
    "        df = df.dropna(axis=1, how=\"all\")\n",
    "        log.warning(f\"Rows: \\n{df.to_string(index=False)}\\n\")\n",
    "\n",
    "    log.warning(\n",
    "        \"Found row(s) with no identifiable attribute. This is not a problem right now \"\n",
    "        \"as identification may be possible during the TEMP Mapping step.\"\n",
    "    )\n",
    "    log.warning(\n",
    "        \"It's recommended to try to identify these rows (by editing its 'best_feature' column) \"\n",
    "        \"in the features_info.tsv file, for better accuracy.\"\n",
    "    )\n",
    "    log.warning(\n",
    "        \"If you wish to try to identify these rows in the TEMP Mapping step, make sure to add\"\n",
    "        \"'no_identifiable_attribute' from feature_names.txt to feature_unks.txt, in the next steps\"\n",
    "    )\n",
    "    log.warning(\n",
    "        \"Another solution is add a new identifying variable to feature_order. This option is \"\n",
    "        \"documented in 'Imports and functions' section of this notebook (first cell).\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837a46ea",
   "metadata": {},
   "source": [
    "#### D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3ed357",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_gdt_compliance = True\n",
    "comment = \"Manual from missing_dbxref_GeneID feature names\"\n",
    "\n",
    "if add_gdt_compliance:\n",
    "    gdt_str = f' #gd MANUAL{ \" #c \" + comment if comment else \"\" }'\n",
    "else:\n",
    "    gdt_str = \"\"\n",
    "\n",
    "# df with 2 columns, one for feature_names and one for in_gene_dict\n",
    "new_df = pd.DataFrame({\"best_feature\": features_info_df[\"best_feature\"].unique()})\n",
    "new_df[\"in_gene_dict\"] = new_df[\"best_feature\"].isin(gene_dict)\n",
    "\n",
    "unique_names = new_df[~new_df[\"in_gene_dict\"]][\"best_feature\"]\n",
    "unique_names = gdt.natural_sort(unique_names)\n",
    "with open(MISC_DIR / \"feature_names.txt\", \"w+\") as f1:\n",
    "    for name in unique_names:\n",
    "        f1.write(f\"{name}{gdt_str}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a3f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d13888a",
   "metadata": {},
   "source": [
    "The user must now parse feature_names.txt  \n",
    "\n",
    "Features that can be easily identifiable must be added to the current  \n",
    "version of the gdict, and features that need deeper investigation should be  \n",
    "copied to a new file name 'feature_unks.txt'\n",
    "  \n",
    "The script will now try to automatically add the gene_ids with feature names   \n",
    "that __are not in 'feature_unks.txt'__ (and therefore known) to gene_dict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870c089b",
   "metadata": {},
   "source": [
    "### Automated Insertion from features_info.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec95b8f",
   "metadata": {},
   "source": [
    "#### A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef05f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the names exist in the gene_dict\n",
    "features_info_df = pd.read_csv(MISC_DIR / \"features_info.tsv\", sep=\"\\t\")\n",
    "\n",
    "names_unk = set()\n",
    "with open(MISC_DIR / \"feature_unks.txt\", \"r\") as f1:\n",
    "    for line in f1:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        if \"#gd\" in line:\n",
    "            line = line.split(\"#gd\")[0].strip()\n",
    "\n",
    "        names_unk.add(line)\n",
    "\n",
    "log.info(\n",
    "    \"Verifing that all feature_names.txt values (excluding those in feature_unks.txt) exist in the newest_gdict_file.\"\n",
    ")\n",
    "gene_dict = gdt.read_gdict(gdict_path, lazy_info=False)\n",
    "log.info(f\"GeneDict loaded from {gdict_path.name}\")\n",
    "log.debug(f\"path: {gdict_path}\")\n",
    "\n",
    "log.info(\"Header:\")\n",
    "for x in gene_dict.header:\n",
    "    log.info(f\"\\t{x}\")\n",
    "\n",
    "log.info(\"GDT Info:\")\n",
    "gdt.log_info(log, gene_dict)\n",
    "\n",
    "names_not_in_dict = set()\n",
    "all_names = set(features_info_df[\"best_feature\"].unique()) - names_unk\n",
    "for name in all_names:\n",
    "    if name not in gene_dict:\n",
    "        names_not_in_dict.add(name)\n",
    "\n",
    "if names_not_in_dict:\n",
    "    log.debug(f\"Warning: {len(names_not_in_dict)} name(s) not in newest_gdict_file!\")\n",
    "    log.debug(\n",
    "        \"These names are not in feature_unk, so you marked them as identifiable. Please identify them or add them feature_unk.\"\n",
    "    )\n",
    "    log.debug(\n",
    "        \"It could also be that you forgot to update and/or reload the newest_gdict_file with the changes you made above.\"\n",
    "    )\n",
    "    [log.debug(name) for name in names_not_in_dict]\n",
    "    raise ValueError(f\"Error: {len(names_not_in_dict)} names not in newest_gdict_file!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715977c6",
   "metadata": {},
   "source": [
    "#### B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e914f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \"automated insertion from missing_dbxref_GeneID best feature\"\n",
    "unique_gene_ids = features_info_df[~features_info_df[\"best_feature\"].isin(names_unk)][\n",
    "    \"gene_id\"\n",
    "].unique()\n",
    "\n",
    "errors = []\n",
    "\n",
    "log.info(\n",
    "    \" ---- [Starting 'Automated insertion of gene_ids with known features from features_info.tsv'] ----\"\n",
    ")\n",
    "for gene_id in unique_gene_ids:\n",
    "    df = features_info_df[features_info_df[\"gene_id\"] == gene_id]\n",
    "\n",
    "    # sanity check, are all feature_names the same?\n",
    "    if df[\"best_feature\"].nunique() != 1:\n",
    "        log.warning(\n",
    "            f\"{gene_id} has multiple best_features: {df['best_feature'].unique()}\"\n",
    "        )\n",
    "        log.debug(\"\\tChecking if they have the same label in gene_dict...\")\n",
    "\n",
    "        labels = {gene_dict[feat].label for feat in df[\"best_feature\"].unique()}\n",
    "        if len(labels) != 1:\n",
    "            log.error(\n",
    "                f\"\\nSkipping {gene_id} as it has multiple best_features with different labels.\"\n",
    "            )\n",
    "            errors.append((gene_id, df[\"best_feature\"].unique(), labels))\n",
    "            continue\n",
    "        else:\n",
    "            log.debug(f\"\\tAll best_features have the same label: {labels.pop()}\")\n",
    "\n",
    "    label = gene_dict[df[\"best_feature\"].iloc[0]].label\n",
    "    an_sources = df[\"seqid\"].unique().tolist()\n",
    "    log.debug(\n",
    "        f\"Adding {gene_id} (bf: {df['best_feature'].iloc[0]}) with label '{label}', an_sources: {an_sources}, comment: {comment}\"\n",
    "    )\n",
    "    gene_dict[gene_id] = gdt.GeneGeneric(label=label, an_sources=an_sources, c=comment)\n",
    "log.info(\n",
    "    \" ---- [Finished 'Automated insertion of gene_ids with known features from features_info.tsv'] ----\"\n",
    ")\n",
    "\n",
    "if errors:\n",
    "    log.warning(\n",
    "        f\"'Multiple best_features with different labels' error in {len(errors)} gene_ids:\"\n",
    "    )\n",
    "    for gene_id, features, labels in errors:\n",
    "        log.warning(f\"{gene_id} has multiple best_features: {features}.\")\n",
    "        log.warning(f\"That points to different labels: {labels}.\\n\")\n",
    "\n",
    "    log.warning(\n",
    "        \"Please check the features_info.tsv file for these gene_id values and fix them.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa44335c",
   "metadata": {},
   "source": [
    "#### C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82329a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path, nth_iteration = increment_gdict_file(gdict_path)\n",
    "log.info(f\"Writing GeneDict to {new_path} | Iteration: {nth_iteration}\")\n",
    "gene_dict.header.append(\n",
    "    f\"{gdt.time_now()} - Data added from 'Automated insertion of gene_ids with known features from features_info.tsv'\"\n",
    ")\n",
    "gene_dict.to_gdict(new_path, overwrite=True)\n",
    "log.info(f\"{new_path.name} was created in misc/gdt!\")\n",
    "log.info(\n",
    "    \"You must now add it to newest_gdict_file in the Setup cell, and rerun the cell\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350d5c33",
   "metadata": {},
   "source": [
    "### TEMP Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58c98d3",
   "metadata": {},
   "source": [
    "#### A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e4d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_dict = gdt.read_gdict(gdict_path, lazy_info=False)\n",
    "log.info(f\"GeneDict loaded from {gdict_path.name}\")\n",
    "log.debug(f\"path: {gdict_path}\")\n",
    "\n",
    "log.info(\"Header:\")\n",
    "for x in gene_dict.header:\n",
    "    log.info(f\"\\t{x}\")\n",
    "\n",
    "log.info(\"GDT Info:\")\n",
    "gdt.log_info(log, gene_dict)\n",
    "\n",
    "names_unk = set()\n",
    "with open(MISC_DIR / \"feature_unks.txt\", \"r\") as f1:\n",
    "    for line in f1:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        if \"#gd\" in line:\n",
    "            line = line.split(\"#gd\")[0].strip()\n",
    "\n",
    "        names_unk.add(line)\n",
    "\n",
    "features_info_df = pd.read_csv(MISC_DIR / \"features_info.tsv\", sep=\"\\t\")\n",
    "features_unk_df = (\n",
    "    features_info_df[features_info_df[\"best_feature\"].isin(names_unk)]\n",
    "    .copy()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "unk_dict = features_unk_df.groupby(\"seqid\")[\"gene_id\"].agg(list).to_dict()\n",
    "log.info(\n",
    "    f\"Found {len(unk_dict)} seqids with unrecognized features in features_info.tsv.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5c540d",
   "metadata": {},
   "source": [
    "#### B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7969df",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_unk = gdt.GeneDict()\n",
    "label_count = 0\n",
    "change_gene_dict = False\n",
    "log.info(\n",
    "    \" ---- [Starting 'AN_missing_dbxref_GeneID matching 'child + parent' best feature pair'] ----\"\n",
    ")\n",
    "for an in unk_dict.keys():\n",
    "    gene_ids = unk_dict[an]\n",
    "    log.debug(f\"AN: {an}| gene_ids: {gene_ids}\")\n",
    "    an_path = gff_builder.build(an)\n",
    "\n",
    "    df = gdt.load_gff3(an_path, usecols=gdt.GFF3_COLUMNS)\n",
    "    df = gdt.filter_orfs(df) if remove_orfs else df\n",
    "\n",
    "    df[\"gene_id\"] = df[\"attributes\"].str.extract(RE_ID, expand=False)\n",
    "    df[\"parent\"] = df[\"attributes\"].str.extract(RE_parent, expand=False)\n",
    "\n",
    "    for name, pattern in re_features.items():\n",
    "        df[name] = df[\"attributes\"].str.extract(pattern, expand=False)\n",
    "\n",
    "    if df[features_order].isna().all(axis=1).any():\n",
    "        # alredy logged in the previous step\n",
    "        df.loc[df[features_order].isna().all(axis=1), \"gene\"] = (\n",
    "            \"no_identifiable_attribute\"\n",
    "        )\n",
    "\n",
    "    # Procedurally fill 'best_feature' based on the order of features_name\n",
    "    df[\"best_feature\"] = df[features_order[0]]\n",
    "    for col in features_order[1:]:\n",
    "        df[\"best_feature\"] = df[\"best_feature\"].fillna(df[col])\n",
    "\n",
    "    for gene_id in gene_ids:\n",
    "        candidates = df[df[\"parent\"] == gene_id]\n",
    "        log.debug(f\" gene_id: {gene_id} | number of candidates: {len(candidates)}\")\n",
    "\n",
    "        # Handle case where no candidates found\n",
    "        if len(candidates) == 0:\n",
    "            log.debug(f\" no candidate with parent={gene_id} found\")\n",
    "            log.debug(\"  adding it to UNKNOWN label\\n\")\n",
    "            temp_unk[gene_id] = gdt.GeneGeneric(\n",
    "                label=f\"{gct}-UNKNOWN\",\n",
    "                an_sources=[an],\n",
    "                c=f\"unknown gene_id from {an}{gff_suffix} | \"\n",
    "                f\"a: {df[df['gene_id'] == gene_id]['attributes'].iloc[0] if not df[df['gene_id'] == gene_id].empty else 'N/A'}\",\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Handle feature name conflicts | TODO check their gene_dict labels\n",
    "        # IMPORTANT\n",
    "        if candidates[\"best_feature\"].nunique() > 1:\n",
    "            log.warning(\n",
    "                \" more than one canditate found, but with best_feature conflict, chosing the first one.\"\n",
    "            )\n",
    "            log.warning(\n",
    "                f\"  best_features: {candidates['best_feature'].unique().to_list()}\"\n",
    "            )\n",
    "\n",
    "        best_feature = candidates[\"best_feature\"].iloc[0]\n",
    "        log.debug(f\"  chosen best_feature: {best_feature}\")\n",
    "        [\n",
    "            log.debug(f\"\\tt: {x.type} | bf: {x.best_feature} | a: {x.attributes}\")\n",
    "            for x in candidates.itertuples()\n",
    "        ]\n",
    "\n",
    "        # Handle case where feature_name is in gene_dict\n",
    "        if best_feature in gene_dict:\n",
    "            change_gene_dict = True\n",
    "            label = gene_dict[best_feature].label\n",
    "            log.debug(f\"  best_feature in gene_dict, label: {label}\\n\")\n",
    "            gene_dict[gene_id] = gdt.GeneGeneric(\n",
    "                label=label,\n",
    "                an_sources=[an],\n",
    "                c=f\"insertion from missing_dbxref_GeneID feature mapping, source: {best_feature} | type: {candidates['type'].iloc[0]}\",\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Handle case where feature_name is NOT in gene_dict\n",
    "        log.debug(f\"  best_feature not in gene_dict: {best_feature}\")\n",
    "        log.debug(\"  checking in temp_unk\")\n",
    "\n",
    "        if best_feature in temp_unk:\n",
    "            label = temp_unk[best_feature].label\n",
    "            log.debug(f\"  found in temp_unk, label: {label}\\n\")\n",
    "            gene_dict[gene_id] = gdt.GeneGeneric(\n",
    "                label=label,\n",
    "                an_sources=[an],\n",
    "                c=f\"insertion from missing_dbxref_GeneID feature mapping, source: {best_feature} | type: {candidates['type'].iloc[0]}\",\n",
    "            )\n",
    "        else:\n",
    "            label_count += 1\n",
    "            label = f\"{gct}-TEMP-{label_count}\"\n",
    "            log.debug(f\"  not found in temp_unk, new label: {label}\\n\")\n",
    "            temp_unk[best_feature] = gdt.GeneDescription(\n",
    "                label=label, source=\"MANUAL\", c=None\n",
    "            )\n",
    "\n",
    "            temp_unk[gene_id] = gdt.GeneGeneric(\n",
    "                label=label,\n",
    "                an_sources=[an],\n",
    "                c=f\"insertion from missing_dbxref_GeneID feature mapping, source: {best_feature} | type: {candidates['type'].iloc[0]}\",\n",
    "            )\n",
    "log.info(\n",
    "    \" ---- [Finished 'AN_missing_dbxref_GeneID matching 'child + parent' best feature pair'] ----\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a47d5",
   "metadata": {},
   "source": [
    "#### C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a790c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "if temp_unk:\n",
    "    temp_path = most_recent_gdict(GDT_DIR, prefix=\"TEMP_Mapping\")\n",
    "    new_path, map_iteration = increment_gdict_file(temp_path)\n",
    "    log.info(f\"Writing TEMP Mapping to {new_path} | Iteration: {map_iteration}\")\n",
    "    temp_unk.header = [\n",
    "        \"version 0.0.2\",\n",
    "        f\"TEMP_Mapping - {map_iteration}\",\n",
    "        f\"{gdt.time_now()} - Automatically generated from 'AN_missing_dbxref_GeneID matching 'child + parent' best feature pair'\",\n",
    "    ]\n",
    "    temp_unk.to_gdict(new_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c94c4e",
   "metadata": {},
   "source": [
    "#### D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b38296",
   "metadata": {},
   "outputs": [],
   "source": [
    "if change_gene_dict:\n",
    "    new_path, nth_iteration = increment_gdict_file(gdict_path)\n",
    "    log.info(f\"Writing GeneDict to {new_path} | pilot itr: {nth_iteration}\")\n",
    "    gene_dict.header.append(\n",
    "        f\"{gdt.time_now()} - Data added from 'AN_missing_dbxref_GeneID matching 'child + parent' best feature pair'\"\n",
    "    )\n",
    "    gene_dict.to_gdict(new_path)\n",
    "    log.info(f\"{new_path.name} was created in misc/gdt!\")\n",
    "    log.info(\n",
    "        \"You must now add it to newest_gdict_file in the Setup cell, and rerun the cell\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857707e0",
   "metadata": {},
   "source": [
    "### Genes exclusion of to_remove_2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e57d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_string = \"discard-\"\n",
    "genes_to_exclude = \"to_exclude_2.txt\"\n",
    "\n",
    "exclude_gene_ids = defaultdict(set)\n",
    "with open(MISC_DIR / genes_to_exclude, \"r\") as f:\n",
    "    for line in f:\n",
    "        if (\n",
    "            not line.strip()\n",
    "            or line.startswith(\"#\")\n",
    "            or line.startswith(\"[\")\n",
    "            or \"#gd\" in line\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        gene_id, an = line.split(\"#c\", 1)[0].split(\"#gn\", 1)\n",
    "        exclude_gene_ids[an.strip()].add(gene_id.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d1705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\n",
    "    \" ---- [Starting 'AN_missing_dbxref_GeneID excluding gene IDs from GFF3s'] ----\"\n",
    ")\n",
    "for an in exclude_gene_ids.keys():\n",
    "    log.info(f\"Processing {an} for excluding {len(exclude_gene_ids[an])} gene IDs\")\n",
    "    log.trace(f\" excluding gene IDs: {exclude_gene_ids[an]}\")\n",
    "    an_path = gff_builder.build(an)\n",
    "    with open(an_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    headers, index = [], 0\n",
    "    while lines[index].startswith(\"#\"):\n",
    "        headers.append(lines[index].strip())\n",
    "        index += 1\n",
    "\n",
    "    pattern = re.compile(\n",
    "        \"|\".join([re.escape(f\"ID={x};\") for x in exclude_gene_ids[an]])\n",
    "    )\n",
    "    log.trace(f\"Pattern for exclusion: {pattern.pattern}\")\n",
    "    contents = []\n",
    "\n",
    "    for line in lines[index:]:\n",
    "        if not (line := line.strip()):\n",
    "            continue\n",
    "        line = line.split(\"\\t\")\n",
    "\n",
    "        # line[2] is type, line[8] is attributes\n",
    "        if pattern.search(line[8]):\n",
    "            if append_string not in line[2]:\n",
    "                line[2] = append_string + line[2]\n",
    "\n",
    "        contents.append(\"\\t\".join(line))\n",
    "\n",
    "    with open(an_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(headers))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\".join(contents))\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "log.info(\n",
    "    \" ---- [Finished 'AN_missing_dbxref_GeneID excluding gene IDs from GFF3s'] ----\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
