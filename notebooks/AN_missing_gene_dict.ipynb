{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8abff2ef",
   "metadata": {},
   "source": [
    "### Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446bdf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from Bio import Entrez\n",
    "\n",
    "import gdt\n",
    "\n",
    "RE_ID = re.compile(r\"ID=([^;]+)\")\n",
    "RE_gene = re.compile(r\"gene=([^;]+)\")\n",
    "RE_dbxref_GeneID = re.compile(r\"Dbxref=.*GeneID:([^;,]+)\")\n",
    "\n",
    "\n",
    "def increment_gdict_file(path):\n",
    "    \"\"\"Increment the GDICT file name by 1.\n",
    "    Example: fungi-ncbi_pilot_03.gdict -> fungi-ncbi_pilot_04.gdict\n",
    "    \"\"\"\n",
    "    plist = path.stem.split(\"_\")\n",
    "    if plist[-1] == \"stripped\":\n",
    "        plist[-1] = \"pilot\"\n",
    "        plist.append(0)\n",
    "\n",
    "    try:\n",
    "        number = int(plist[-1]) + 1\n",
    "        plist[-1] = f\"{number:02d}\"\n",
    "    except ValueError:\n",
    "        raise ValueError(\n",
    "            f\"Invalid GDICT file name: {path.name}. Expected format: <preferred_name>_##.gdict, where ## is a number.\"\n",
    "        )\n",
    "    return path.parent / f'{\"_\".join(plist)}{path.suffix}', number\n",
    "\n",
    "\n",
    "def most_recent_gdict(dir_path, prefix):\n",
    "    \"\"\"Get the most recent gdict file in the directory.\n",
    "\n",
    "    Arguments:\n",
    "        dir_path (Path): Directory to search for GDICT files.\n",
    "        prefix (str): Prefix of the GDICT files to search for. It will match files like \"*<prefix>*.gdict\".\n",
    "\n",
    "    Returns:\n",
    "        Path: Path to the most recent GDICT file.\n",
    "\n",
    "    \"\"\"\n",
    "    temp_files = list(\n",
    "        dir_path.glob(f\"*{prefix}*.gdict\")\n",
    "    )  # maybe change to check for numbers after prefix?\n",
    "    if not temp_files:\n",
    "        return dir_path / f\"{prefix}_00.gdict\"\n",
    "    return gdt.natural_sort(temp_files, key=lambda x: x.stem)[-1]\n",
    "\n",
    "\n",
    "def data_process(\n",
    "    df_missing,\n",
    "    AN,\n",
    "    gene_dict,\n",
    "    temp_gene_dict,\n",
    "    gct,\n",
    "    temp_count,\n",
    "    log,\n",
    "    use_NCBI_symbol=False,\n",
    "    use_gene=False,\n",
    "    temp_name=\"temp_desc\",\n",
    "    c_text=\"ncbi_desc\",\n",
    "    gn_tag=\"NCBI\",\n",
    "):\n",
    "    \"\"\"Process the data in the dataframe and update the gene_dict and corresponding temp_gene_dict.\n",
    "\n",
    "    Args:\n",
    "        df_missing (pd.DataFrame): DataFrame containing missing gene information.\n",
    "        AN (str): Annotation source identifier.\n",
    "        gene_dict (GeneDict): Dictionary to store gene information.\n",
    "        temp_gene_dict (GeneDict): Temporary dictionary for gene descriptions.\n",
    "        gct (str): Genetic compartment, MIT or PLT (for now).\n",
    "        temp_count (int): Counter for temporary labels.\n",
    "        log (GDTLogger): Logger instance for logging debug information.\n",
    "        use_NCBI_symbol (bool): Whether to use NCBI gene symbols. Default is False, so it uses gene descriptions.\n",
    "        use_gene (bool): Whether to use the 'gene' field instead of NCBI information.\n",
    "        temp_name (str): Name for the temporary dictionary.\n",
    "        c_text (str): Text to be used in the '#c' field of the GeneDbxref object.\n",
    "        gn_tag (str): Tag for the source of the gene description.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated gene_dict, temp_gene_dict, and temp_count.\n",
    "\n",
    "    \"\"\"\n",
    "    for row in df_missing.itertuples():\n",
    "        check_var = row.gene_symbol if use_NCBI_symbol else row.desc\n",
    "        check_var = row.gene if use_gene else check_var\n",
    "        check_desc = (\n",
    "            f\"{check_var} | ncbi_desc: {row.desc}\" if use_NCBI_symbol else check_var\n",
    "        )\n",
    "\n",
    "        log.trace(\n",
    "            f\"gene_id: {row.gene_id} | dbxref: {row.dbxref} | att: {row.attributes}\"\n",
    "        )\n",
    "        log.trace(f\"\\t{check_var = } | {use_gene = } | {use_NCBI_symbol = }\")\n",
    "        log.trace(f\"\\t{row.other_aliases = } | {row.desc = } | {row.gene_symbol = }\")\n",
    "\n",
    "        if check_var in gene_dict:\n",
    "            gene_label = gene_dict[check_var].label\n",
    "            log.trace(\n",
    "                f\"\\t[1st T]check_var found in gene_dict, L: |{gene_label}| adding: {row.gene_id} #dx {AN}:{row.dbxref} #c {c_text}: {check_desc}\"\n",
    "            )\n",
    "            gene_dict[row.gene_id] = gdt.DbxrefGeneID(\n",
    "                label=gene_label,\n",
    "                an_source=AN,\n",
    "                GeneID=row.dbxref,\n",
    "                c=f\"{c_text}: {check_desc}\",\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            log.trace(\n",
    "                f\"\\t[1st F]check_var not found in gene_dict | checking {temp_name} | Label: {check_var}\"\n",
    "            )\n",
    "\n",
    "            if check_var in temp_gene_dict:\n",
    "                gene_label = temp_gene_dict[check_var].label\n",
    "                log.trace(\n",
    "                    f\"\\t[2nd T]check_var found in {temp_name}, L: |{gene_label}| adding: {row.gene_id} #dx {AN}:{row.dbxref} #c {c_text}: {check_desc}\"\n",
    "                )\n",
    "                temp_gene_dict[row.gene_id] = gdt.DbxrefGeneID(\n",
    "                    label=gene_label,\n",
    "                    an_source=AN,\n",
    "                    GeneID=row.dbxref,\n",
    "                    c=f\"{c_text}: {check_desc}\",\n",
    "                )\n",
    "            else:\n",
    "\n",
    "                temp_count += 1\n",
    "                label = f\"{gct}-TEMP-{temp_count}\"\n",
    "                log.trace(\n",
    "                    f\"\\t[2nd F]check_var not found in {temp_name}, new label |{label}| adding: {row.gene_id} #dx {AN}:{row.dbxref} #c {c_text}: {check_desc}\"\n",
    "                )\n",
    "                temp_gene_dict[check_var] = gdt.GeneDescription(\n",
    "                    label=label, source=gn_tag, c=None\n",
    "                )\n",
    "\n",
    "                temp_gene_dict[row.gene_id] = gdt.DbxrefGeneID(\n",
    "                    label=label,\n",
    "                    an_source=AN,\n",
    "                    GeneID=row.dbxref,\n",
    "                    c=f\"{c_text}: {check_desc}\",\n",
    "                )\n",
    "\n",
    "    return gene_dict, temp_gene_dict, temp_count\n",
    "\n",
    "\n",
    "def check_envs(env_path):\n",
    "    try:\n",
    "        import dotenv\n",
    "\n",
    "        dotenv.load_dotenv(env_path)\n",
    "\n",
    "    except ImportError:\n",
    "        print(\n",
    "            \"Since the 'dotenv' package is not installed, check_envs will only check environment variables.\"\n",
    "        )\n",
    "\n",
    "    email = os.getenv(\"ENTREZ_EMAIL\")\n",
    "    api_key = os.getenv(\"ENTREZ_API_KEY\")\n",
    "\n",
    "    if email:\n",
    "        print(f\"Loading email: {email}\")\n",
    "        Entrez.email = os.getenv(\"ENTREZ_EMAIL\")\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Entrez email is not set in the environment variables either,\\n\"\n",
    "            \"so please set it in the Setup cell, or set the environment variable 'ENTREZ_EMAIL' directly,\\n\"\n",
    "            \"or create an .env file with it, and pass its path to check_envs.\"\n",
    "        )\n",
    "\n",
    "    if api_key:\n",
    "        print(\"NCBI API Key found, loading it.\")\n",
    "        Entrez.api_key = api_key\n",
    "    elif not Entrez.api_key:\n",
    "        print(\n",
    "            \"Entrez API key is defined, neither set up in the environment variables.\\n\"\n",
    "            \"This will limit the number of requests per second to NCBI to 3, as per\\n\"\n",
    "            \"Biopython Entrez guidelines: https://biopython.org/docs/1.76/api/Bio.Entrez.html \"\n",
    "        )\n",
    "\n",
    "\n",
    "def time_now():\n",
    "    \"\"\"Returns current time in YYYY-MM-DD HH:MM format.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abbc353",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a03048",
   "metadata": {},
   "source": [
    "#### A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822b5b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines all the global variables used in the script.\n",
    "# Change these variables to match your local setup.\n",
    "# The most_recent_gdt_file variable should be set to the path of the most recent GDT file,\n",
    "# OR the stripped GDT file used in filter command, if applicable.\n",
    "# gct = genetic_compartment\n",
    "\n",
    "DATA_DIR = \"/home/brenodupin/matheus/ig_pipeline/new_run/fungi_mit\"\n",
    "newest_gdict_file = \"fungi_mit_pilot_05.gdict\"\n",
    "global_query_string = gdt.QS_GENE_TRNA_RRNA\n",
    "remove_orfs = True\n",
    "in_folder = True\n",
    "gct = \"MIT\"\n",
    "gff_ext = \".gff3\"\n",
    "gff_suffix = \"\"\n",
    "\n",
    "Entrez.email = \"\"\n",
    "Entrez.api_key = \"\"\n",
    "\n",
    "print(f\"Chosen feature query string: '{global_query_string}'\\n\")\n",
    "\n",
    "# just checking\n",
    "DATA_DIR = Path(DATA_DIR).resolve()\n",
    "if not DATA_DIR.is_dir():\n",
    "    raise FileNotFoundError(f\"Path {DATA_DIR} is not a directory.\")\n",
    "\n",
    "MISC_DIR = DATA_DIR / \"misc\"\n",
    "GDT_DIR = MISC_DIR / \"gdt\"\n",
    "GDT_DIR.mkdir(511, True, True)  # 511 = 0o777\n",
    "\n",
    "AN_missing_gene_dict = MISC_DIR / \"AN_missing_gene_dict.txt\"\n",
    "\n",
    "if not AN_missing_gene_dict.is_file():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Missing {AN_missing_gene_dict}, did you run gdt-cli filter?\"\n",
    "    )\n",
    "    pass\n",
    "\n",
    "if \"newest_gdict_file\" in globals():\n",
    "    gdict_path = GDT_DIR / newest_gdict_file\n",
    "    if not gdict_path.is_file():\n",
    "        print(\n",
    "            f\"Not found {gdict_path.name}, does it exist in misc/gdt?\\nGDICTs in {GDT_DIR}:\"\n",
    "        )\n",
    "        [print(f\" - {f.name}\") for f in sorted(GDT_DIR.glob(\"*.gdt\"))]\n",
    "        raise FileNotFoundError(\n",
    "            f\"Most recent GDIDT file {gdict_path.name} does not exist in {GDT_DIR}.\"\n",
    "        )\n",
    "else:\n",
    "    print(\n",
    "        \"Warning: 'newest_gdict_file' variable not set.\\n\\n\"\n",
    "        \"If you have a previous GDICT file:\\n\"\n",
    "        \"• Set the newest_gdict_file variable\\n\"\n",
    "        \"• Re-run this cell\\n\\n\"\n",
    "        \"If you intend to run this without a GDICT file, this warning can be ignored.\"\n",
    "    )\n",
    "    # to simplify the code, a exetution without newest_gdict_file\n",
    "    # basically the same as with one, but with and empty gdt file\n",
    "    gdict_path = GDT_DIR / \"pilot_00.gdict\"\n",
    "    gdt.create_empty_gdt(gdict_path)\n",
    "\n",
    "if in_folder:\n",
    "    gff_builder = gdt.GFFPathBuilder().use_folder_builder(\n",
    "        DATA_DIR,\n",
    "        gff_suffix,\n",
    "        gff_ext,\n",
    "    )\n",
    "else:\n",
    "    gff_builder = gdt.GFFPathBuilder().use_standard_builder(\n",
    "        DATA_DIR,\n",
    "        gff_suffix,\n",
    "        gff_ext,\n",
    "    )\n",
    "print(f\"Using GFF builder: {gff_builder}\\n\")\n",
    "\n",
    "if not Entrez.email:\n",
    "    print(\"Entrez email not set, checking if it's in a .env or in the environment.\")\n",
    "    check_envs(\".env\")\n",
    "\n",
    "print(\"\\nEverything is set up, no problems found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132dad79",
   "metadata": {},
   "source": [
    "#### b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61084bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = MISC_DIR / \"03_missing_gene_dict.log\"\n",
    "\n",
    "log = gdt.create_simple_logger(\n",
    "    print_to_console=True,\n",
    "    console_level=\"DEBUG\",\n",
    "    save_to_file=True,\n",
    "    file_level=\"TRACE\",\n",
    "    log_file=log_file,\n",
    ")\n",
    "log.debug(\"Running from notebook AN_missing_gene_dict.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f30404",
   "metadata": {},
   "source": [
    "### TEMP First Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4a9ed0",
   "metadata": {},
   "source": [
    "#### A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64970dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(AN_missing_gene_dict, \"r\") as f:\n",
    "    ANs = [line.strip() for line in f.readlines() if line.strip()]\n",
    "log.info(f\"Found {len(ANs)} ANs in {AN_missing_gene_dict}\")\n",
    "log.trace(f\"ANs: {ANs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8bd601",
   "metadata": {},
   "source": [
    "#### B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3ad533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GDICT file (even if empty)\n",
    "gene_dict = gdt.read_gdict(gdict_path, lazy_info=False)\n",
    "log.info(f\"GeneDict loaded from {gdict_path.name}\")\n",
    "log.debug(f\"path: {gdict_path}\")\n",
    "\n",
    "log.info(\"Header:\")\n",
    "for x in gene_dict.header:\n",
    "    log.info(f\"\\t{x}\")\n",
    "\n",
    "log.info(\"GDT Info:\")\n",
    "gdt.log_info(log, gene_dict)\n",
    "\n",
    "# set up the temporary gene dictionary\n",
    "temp_gene_dict = gdt.GeneDict()\n",
    "temp_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0df6622",
   "metadata": {},
   "source": [
    "#### C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "\n",
    "log.info(\n",
    "    \" ---- [Starting 'AN_missing_gene_dict parsing gene= + NCBI Description'] ----\"\n",
    ")\n",
    "for i, AN in enumerate(ANs):\n",
    "    log.debug(f\"-- [Processing: {AN}] --\")\n",
    "\n",
    "    an_path = gff_path(AN)\n",
    "    if not an_path.exists():\n",
    "        log.error(f\"Error: {AN} does not exist (an_path: {an_path})\")\n",
    "        errors.append((AN, f\"File not found, expected path: {an_path}\"))\n",
    "        continue\n",
    "\n",
    "    df = gdt.load_gff3(an_path, query_string=global_query_string)\n",
    "    df = gdt.filter_orfs(df) if remove_orfs else df\n",
    "\n",
    "    df[\"gene_id\"] = df[\"attributes\"].str.extract(RE_ID, expand=False)\n",
    "    df[\"in_gene_dict\"] = df[\"gene_id\"].isin(gene_dict)\n",
    "\n",
    "    df[\"gene\"] = df[\"attributes\"].str.extract(RE_gene, expand=False)\n",
    "    df[\"has_gene\"] = df[\"gene\"].notna()\n",
    "\n",
    "    df[\"dbxref\"] = df[\"attributes\"].str.extract(RE_dbxref_GeneID, expand=False)\n",
    "\n",
    "    df_missing = df[~df[\"in_gene_dict\"] & ~df[\"has_gene\"]].copy()\n",
    "    df_gene = df[~df[\"in_gene_dict\"] & df[\"has_gene\"]].copy()\n",
    "\n",
    "    # process of 'gene='\n",
    "    if not df_gene.empty:\n",
    "        log.debug(\n",
    "            f\"Found {len(df_gene)} feature(s) with gene= in {AN}, not in gene_dict.\"\n",
    "        )\n",
    "        df_gene[[\"other_aliases\", \"desc\", \"gene_symbol\"]] = [\n",
    "            \"no_other_aliases\",\n",
    "            \"no_description\",\n",
    "            \"no_gene_symbol\",\n",
    "        ]\n",
    "        gene_dict, temp_gene_dict, temp_count = data_process(\n",
    "            df_gene,\n",
    "            AN,\n",
    "            gene_dict,\n",
    "            temp_gene_dict,\n",
    "            gct,\n",
    "            temp_count,\n",
    "            log,\n",
    "            use_gene=True,\n",
    "            temp_name=\"temp_gene\",\n",
    "            c_text=\"gff_gene\",\n",
    "            gn_tag=\"gff_gene\",\n",
    "        )\n",
    "\n",
    "    if df_missing.empty:\n",
    "        log.debug(\n",
    "            \"All features are either in gene_dict or have a gene= attribute and have \"\n",
    "            \"been already processed. Skipping.\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # search NCBI\n",
    "    query_ids = \",\".join(df_missing[\"dbxref\"].unique())\n",
    "    try:\n",
    "        with Entrez.esummary(db=\"gene\", id=query_ids) as search_handle:\n",
    "            search_results = Entrez.read(search_handle)[\"DocumentSummarySet\"][\"DocumentSummary\"]  # type: ignore\n",
    "\n",
    "    except (RuntimeError, KeyError, Exception) as ex:\n",
    "        log.error(f\"{AN} got the error in try/except: {ex}\")\n",
    "        errors.append((AN, f\"Entrez.read: {ex}\"))\n",
    "        continue\n",
    "\n",
    "    if len(search_results) != len(df_missing[\"dbxref\"].unique()):\n",
    "        log.warning(\n",
    "            f\"Number of search results ({len(search_results)}) does not match number of dbxrefs ({len(df_missing['dbxref'].unique())}) for {AN}.\"\n",
    "        )\n",
    "        missing_dbxrefs = set(df_missing[\"dbxref\"].unique()) - set(\n",
    "            x.attributes[\"uid\"] for x in search_results\n",
    "        )\n",
    "        log.warning(f\"Missing dbxrefs: {missing_dbxrefs}\")\n",
    "        log.warning(\"The missing dbxrefs will be under the 'no_description' label.\")\n",
    "\n",
    "    # format the search results into a DataFrame\n",
    "    temp_df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"dbxref\": x.attributes[\"uid\"],\n",
    "                \"other_aliases\": x.get(\"OtherAliases\", \"no_other_aliases\"),\n",
    "                \"desc\": x.get(\"Description\", \"no_description\"),\n",
    "                \"gene_symbol\": x.get(\"Name\", \"no_gene_symbol\"),\n",
    "            }\n",
    "            for x in search_results\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    df_merged = df_missing.merge(temp_df, on=\"dbxref\", how=\"left\", copy=False)\n",
    "\n",
    "    # in case NCBI did not return any results for some dbxrefs\n",
    "    df_merged[\"other_aliases\"] = df_merged[\"other_aliases\"].fillna(\"no_other_aliases\")\n",
    "    df_merged[\"desc\"] = df_merged[\"desc\"].fillna(\"no_description\")\n",
    "    df_merged[\"gene_symbol\"] = df_merged[\"gene_symbol\"].fillna(\"no_gene_symbol\")\n",
    "\n",
    "    # process of ncbi description\n",
    "    gene_dict, temp_gene_dict, temp_count = data_process(\n",
    "        df_merged,\n",
    "        AN,\n",
    "        gene_dict,\n",
    "        temp_gene_dict,\n",
    "        gct,\n",
    "        temp_count,\n",
    "        log,\n",
    "    )\n",
    "\n",
    "\n",
    "log.info(\n",
    "    \" ---- [Finished 'AN_missing_gene_dict parsing gene= + NCBI Description'] ----\"\n",
    ")\n",
    "if errors:\n",
    "    log.warning(f\"Errors: {len(errors)}\")\n",
    "    for an, msg in errors:\n",
    "        log.warning(f\"  {an} - {msg}\")\n",
    "\n",
    "    log.warning(\n",
    "        \"Entrez.read errors: This is usually a sporadic event or invalid database references.\"\n",
    "    )\n",
    "    log.warning(\"Next steps to diagnose:\")\n",
    "    log.warning(\n",
    "        \"1. Manually verify a few dbxrefs from your GFF file by searching them in NCBI\"\n",
    "    )\n",
    "    log.warning(\"2. If the dbxrefs are valid in NCBI:\")\n",
    "    log.warning(\"   - Save the current gene_dict as your latest GDICT file,\")\n",
    "    log.warning(\"     and update it at the Setup.\")\n",
    "    log.warning(\"   - Re-run this section (the issue was likely temporary)\")\n",
    "    log.warning(\"3. If the dbxrefs are invalid/obsolete:\")\n",
    "    log.warning(\"   - Option A: Remove said ANs from your dataset\")\n",
    "    log.warning(\"   - Option B: Manually remove ANs from AN_missing_gene_dict.txt)\")\n",
    "    log.warning(\"     and add those ANs to AN_missing_dbxref.txt instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e750afd1",
   "metadata": {},
   "source": [
    "#### D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc2b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if temp_gene_dict:\n",
    "    temp_path = most_recent_gdict(GDT_DIR, prefix=\"TEMP_Description\")\n",
    "    new_path, nth_iteration = increment_gdict_file(temp_path)\n",
    "    log.info(f\"Writing TEMP_Description to {new_path} | Iteration: {nth_iteration}\")\n",
    "    temp_gene_dict.header = [\n",
    "        \"version 0.0.2\",\n",
    "        f\"TEMP_Description - {nth_iteration}\",\n",
    "        f\"{time_now()} - Automatically generated from 'AN_missing_gene_dict parsing gene= + NCBI Description'\",\n",
    "    ]\n",
    "    temp_gene_dict.to_gdict(new_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cd18eb",
   "metadata": {},
   "source": [
    "#### E."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363af008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving gene_dict with the new data, dont forget to change the newest_gdict_file variable\n",
    "new_path, nth_iteration = increment_gdict_file(gdict_path)\n",
    "log.info(f\"Writing GeneDict to {new_path} | Iteration: {nth_iteration}\")\n",
    "gene_dict.header.append(\n",
    "    f\"{time_now()} - Data added from 'AN_missing_gene_dict parsing gene= + NCBI Description'\"\n",
    ")\n",
    "gene_dict.to_gdict(new_path, overwrite=True)\n",
    "log.info(f\"{new_path.name} was created in misc/gdt!\")\n",
    "log.info(\n",
    "    \"You must now add it to newest_gdict_file in the Setup cell, and rerun the cell\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728db9b1",
   "metadata": {},
   "source": [
    "### TEMP Second Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bcdbfd",
   "metadata": {},
   "source": [
    "#### A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c69f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANS_Symbol = set()\n",
    "\n",
    "with open(MISC_DIR / \"seed_TEMP_Symbol.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "\n",
    "        if not line or line.startswith(\"#\") or line.startswith(\"[\") or \"#gd\" in line:\n",
    "            continue  # skip these lines\n",
    "\n",
    "        try:\n",
    "            ANS_Symbol.add(line.split(\"#dx\", 1)[1].strip().split(\":\", 1)[0])\n",
    "        except IndexError:\n",
    "            log.warning(f\"Check this line: {line}\")\n",
    "            continue\n",
    "log.debug(f\"If you had any warnings, check them and rerun this step.\")\n",
    "log.info(f\"Found {len(ANS_Symbol)} ANs in seed_TEMP_Symbol.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c6dd0e",
   "metadata": {},
   "source": [
    "#### B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4da521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GDICT file (even if empty),\n",
    "# if you are running this right after the previous step,\n",
    "# dont forget to change the newest_gdict_file variable\n",
    "# and re-run the setup\n",
    "\n",
    "gene_dict = gdt.read_gdict(gdict_path, lazy_info=False)\n",
    "log.info(f\"GeneDict loaded from {gdict_path.name}\")\n",
    "log.debug(f\"path: {gdict_path}\")\n",
    "\n",
    "log.info(\"Header:\")\n",
    "for x in gene_dict.header:\n",
    "    log.info(f\"\\t{x}\")\n",
    "\n",
    "log.info(\"GDT Info:\")\n",
    "gdt.log_info(log, gene_dict)\n",
    "\n",
    "temp_symbol_gene_dict = gdt.GeneDict()\n",
    "temp_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2810cd1",
   "metadata": {},
   "source": [
    "#### C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55886959",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "\n",
    "log.info(\" ---- [Starting 'AN_missing_gene_dict parsing NCBI Gene Symbol'] ----\")\n",
    "for i, AN in enumerate(ANS_Symbol):\n",
    "    log.debug(f\"-- [Processing: {AN}] --\")\n",
    "\n",
    "    an_path = gff_builder.build(AN)\n",
    "    if not an_path.exists():\n",
    "        log.error(f\"Error: {AN} does not exist (an_path: {an_path})\")\n",
    "        errors.append((AN, \"File not found\"))\n",
    "        continue\n",
    "\n",
    "    df = gdt.load_gff3(an_path, query_string=global_query_string)\n",
    "    df = gdt.filter_orfs(df) if remove_orfs else df\n",
    "\n",
    "    # getting the gene_id and if it is in the gene_dict\n",
    "    df[\"gene_id\"] = df[\"attributes\"].str.extract(RE_ID, expand=False)\n",
    "    df[\"in_gene_dict\"] = df[\"gene_id\"].isin(gene_dict)\n",
    "\n",
    "    # two step method to extract dbxref, first try to get the full dbxref,\n",
    "    # if not all genes are numeric and not NaN, fallback to GeneID,\n",
    "    # check again if all genes are numeric and not NaN.\n",
    "    # if not, raise an error\n",
    "    df[\"dbxref\"] = df[\"attributes\"].str.extract(RE_dbxref_GeneID, expand=False)\n",
    "\n",
    "    df_missing = df[~df[\"in_gene_dict\"]].copy()\n",
    "    if df_missing.empty:\n",
    "        log.debug(\"All features are in gene_dict. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # search NCBI\n",
    "    with Entrez.esummary(\n",
    "        db=\"gene\", id=\",\".join(df_missing[\"dbxref\"].unique())\n",
    "    ) as search_handle:\n",
    "        try:\n",
    "            search_results = Entrez.read(search_handle)[\"DocumentSummarySet\"][\"DocumentSummary\"]  # type: ignore\n",
    "        except (RuntimeError, KeyError, Exception) as ex:\n",
    "            log.error(f\"{ex} in Entrez.read for {AN}\")\n",
    "            errors.append((AN, \"Entrez.read\"))\n",
    "            continue\n",
    "\n",
    "    if len(search_results) != len(df_missing[\"dbxref\"].unique()):\n",
    "        log.warning(\n",
    "            f\"Number of search results ({len(search_results)}) does not match number of dbxrefs ({len(df_missing['dbxref'].unique())}) for {AN}.\"\n",
    "        )\n",
    "        missing_dbxrefs = set(df_missing[\"dbxref\"].unique()) - set(\n",
    "            x.attributes[\"uid\"] for x in search_results\n",
    "        )\n",
    "        log.warning(f\"Missing dbxrefs: {missing_dbxrefs}\")\n",
    "        log.warning(\"The missing dbxrefs will be under the 'no_description' tag.\")\n",
    "\n",
    "    # format the search results into a DataFrame\n",
    "    temp_df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"dbxref\": x.attributes[\"uid\"],\n",
    "                \"other_aliases\": x.get(\"OtherAliases\", \"no_other_aliases\"),\n",
    "                \"desc\": x.get(\"Description\", \"no_description\"),\n",
    "                \"gene_symbol\": x.get(\"Name\", \"no_gene_symbol\"),\n",
    "            }\n",
    "            for x in search_results\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    df_merged = df_missing.merge(temp_df, on=\"dbxref\", how=\"left\", copy=False)\n",
    "\n",
    "    # in case NCBI did not return any results for some dbxrefs\n",
    "    df_merged[\"other_aliases\"] = df_merged[\"other_aliases\"].fillna(\"no_other_aliases\")\n",
    "    df_merged[\"desc\"] = df_merged[\"desc\"].fillna(\"no_description\")\n",
    "    df_merged[\"gene_symbol\"] = df_merged[\"gene_symbol\"].fillna(\"no_gene_symbol\")\n",
    "\n",
    "    # process of ncbi gene sym,bol\n",
    "    gene_dict, temp_symbol_gene_dict, temp_count = data_process(\n",
    "        df_merged,\n",
    "        AN,\n",
    "        gene_dict,\n",
    "        temp_symbol_gene_dict,\n",
    "        gct,\n",
    "        temp_count,\n",
    "        log,\n",
    "        temp_name=\"temp_symbol\",\n",
    "        use_NCBI_symbol=True,\n",
    "        c_text=\"ncbi_symbol\",\n",
    "    )\n",
    "\n",
    "\n",
    "log.info(\" ---- [Finished 'AN_missing_gene_dict parsing NCBI Gene Symbol'] ----\")\n",
    "if errors:\n",
    "    log.warning(f\"Errors: {len(errors)}\")\n",
    "    for an, msg in errors:\n",
    "        log.warning(f\"  {an} - {msg}\")\n",
    "    log.warning(\n",
    "        \"Entrez.read errors: This is usually a sporadic event or invalid database references.\"\n",
    "    )\n",
    "    log.warning(\"Next steps to diagnose:\")\n",
    "    log.warning(\n",
    "        \"1. Manually verify a few dbxrefs from your GFF file by searching them in NCBI\"\n",
    "    )\n",
    "    log.warning(\"2. If the dbxrefs are valid in NCBI:\")\n",
    "    log.warning(\"   - Save the current gene_dict as your latest GDT file\")\n",
    "    log.warning(\"   - Re-run this section (the issue was likely temporary)\")\n",
    "    log.warning(\"3. If the dbxrefs are invalid/obsolete:\")\n",
    "    log.warning(\"   - Option A: Remove said ANs from your dataset\")\n",
    "    log.warning(\"   - Option B: Manually remove ANs from AN_missing_gene_dict.txt)\")\n",
    "    log.warning(\"     and add those ANs to AN_missing_dbxref.txt instead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828bbca",
   "metadata": {},
   "source": [
    "#### D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2a7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if temp_symbol_gene_dict:\n",
    "    temp_path = most_recent_gdict(GDT_DIR, prefix=\"TEMP_Symbol\")\n",
    "    new_path, symbol_iteration = increment_gdict_file(temp_path)\n",
    "    log.info(f\"Writing TEMP Symbol to {new_path} | Iteration: {symbol_iteration}\")\n",
    "    temp_symbol_gene_dict.header = [\n",
    "        \"version 0.0.2\",\n",
    "        f\"TEMP Symbol - {symbol_iteration}\",\n",
    "        f\"{time_now()} - Automatically generated from 'AN_missing_gene_dict parsing NCBI Gene Symbol'\",\n",
    "    ]\n",
    "    temp_symbol_gene_dict.to_gdict(new_path, overwrite=True)\n",
    "else:\n",
    "    log.info(\n",
    "        \"No TEMP Symbol GDT file created, meaning no unknown gene symbols were found.\"\n",
    "    )\n",
    "    symbol_iteration = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb95e7f",
   "metadata": {},
   "source": [
    "#### E."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5d9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving gene_dict with the new data, dont forget to change the newest_gdict_file variable\n",
    "new_path, nth_iteration = increment_gdict_file(gdict_path)\n",
    "log.info(f\"Writing GeneDict to {new_path} | pilot itr: {nth_iteration}\")\n",
    "gene_dict.header.append(\n",
    "    f\"{time_now()} - Data added from 'AN_missing_gene_dict parsing NCBI Gene Symbol'\"\n",
    ")\n",
    "gene_dict.to_gdict(new_path, overwrite=True)\n",
    "log.info(f\"{new_path.name} was created in misc/gdt!\")\n",
    "log.info(\n",
    "    \"You must now add it to newest_gdict_file in the Setup cell, and rerun the cell\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d69fe05",
   "metadata": {},
   "source": [
    "### Genes exclusion of to_remove.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8a356f",
   "metadata": {},
   "source": [
    "#### A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1c6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_string = \"discard-\"\n",
    "genes_to_exclude = \"to_exclude.txt\"\n",
    "\n",
    "exclude_gene_ids = defaultdict(set)\n",
    "with open(MISC_DIR / genes_to_exclude, \"r\") as f:\n",
    "    for line in f:\n",
    "        if (\n",
    "            not line.strip()\n",
    "            or line.startswith(\"#\")\n",
    "            or line.startswith(\"[\")\n",
    "            or \"#gd\" in line\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            gene_id, an = line.split(\"#c\", 1)[0].split(\"#dx\", 1)\n",
    "            an = an.split(\":\", 1)[0].strip()\n",
    "            exclude_gene_ids[an].add(gene_id.strip())\n",
    "        except ValueError:\n",
    "            log.warning(f\"Check this line: {line.strip()}\")\n",
    "            continue\n",
    "\n",
    "log.info(f\"Found {len(exclude_gene_ids)} ANs in {genes_to_exclude}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fcb5aa",
   "metadata": {},
   "source": [
    "#### B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17773f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\" ---- [Starting 'AN_missing_gene_dict excluding gene IDs from GFF3s'] ----\")\n",
    "for an in exclude_gene_ids.keys():\n",
    "    log.info(f\"Processing {an} for excluding {len(exclude_gene_ids[an])} gene IDs\")\n",
    "    log.trace(f\" excluding gene IDs: {exclude_gene_ids[an]}\")\n",
    "    an_path = gff_builder.build(an)\n",
    "    with open(an_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    headers, index = [], 0\n",
    "    while lines[index].startswith(\"#\"):\n",
    "        headers.append(lines[index].strip())\n",
    "        index += 1\n",
    "\n",
    "    pattern = re.compile(\"|\".join([f\"ID={x};\" for x in exclude_gene_ids[an]]))\n",
    "    log.trace(f\"Pattern for exclusion: {pattern.pattern}\")\n",
    "    contents = []\n",
    "\n",
    "    for line in lines[index:]:\n",
    "        if not (line := line.strip()):\n",
    "            continue\n",
    "        line = line.split(\"\\t\")\n",
    "\n",
    "        # line[2] is type, line[8] is attributes\n",
    "        if pattern.search(line[8]):\n",
    "            if append_string not in line[2]:\n",
    "                line[2] = append_string + line[2]\n",
    "\n",
    "        contents.append(\"\\t\".join(line))\n",
    "\n",
    "    with open(an_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(headers))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\".join(contents))\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "log.info(\" ---- [Finished 'AN_missing_gene_dict excluding gene IDs from GFF3s'] ----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
