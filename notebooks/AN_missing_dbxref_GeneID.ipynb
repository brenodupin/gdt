{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9664aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and functions\n",
    "import re\n",
    "import gdt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "RE_ID = re.compile(r\"ID=([^;]+)\")\n",
    "RE_parent = re.compile(r\"Parent=([^;]+)\")\n",
    "\n",
    "# Regex patterns for extracting GFF attributes\n",
    "RE_gene = re.compile(r\"gene=([^;]+)\")\n",
    "RE_product = re.compile(r\"product=([^;]+)\")\n",
    "RE_description = re.compile(r\"description=([^;]+)\")\n",
    "RE_name = re.compile(r\"Name=([^;]+)\")\n",
    "RE_note = re.compile(r\"Note=([^;]+)\")\n",
    "RE_gene_synonym = re.compile(r\"gene_synonym=([^;]+)\")\n",
    "\n",
    "# Features to extract from GFF files (must match the regex names above without RE_ prefix)\n",
    "# ORDER MATTERS: Listed from most descriptive/best for identification to least descriptive\n",
    "# This order determines the priority for filling the feature_name column - earlier entries take precedence\n",
    "features_name = [\"gene\", \"product\", \"description\", \"name\", \"note\", \"gene_synonym\"]\n",
    "\n",
    "# To add a new feature for extraction:\n",
    "# 1. Create a regex pattern with the naming convention: RE_{feature_name}\n",
    "#    Use any regex pattern that captures the desired value from GFF files.\n",
    "#    Common pattern: RE_{feature_name} = re.compile(r\"{attribute_name}=([^;]+)\")\n",
    "#    but you can customize the regex to capture exactly what you need.\n",
    "#\n",
    "# 2. Add the feature name (without RE_ prefix) to the features_name list\n",
    "#    IMPORTANT: Place it in the appropriate position based on how descriptive/useful\n",
    "#    it is for identification. More descriptive features should come first in the list.\n",
    "#\n",
    "# Example - to extract 'locus_tag' attributes:\n",
    "# RE_locus_tag = re.compile(r\"locus_tag=([^;]+)\")  # or any custom regex\n",
    "# features_name = [\"locus_tag\", \"gene\", \"product\", \"description\", \"name\", \"note\", \"gene_synonym\"]  # if locus_tag is most descriptive\n",
    "# # OR\n",
    "# features_name = [\"gene\", \"product\", \"description\", \"locus_tag\", \"name\", \"note\", \"gene_synonym\"]  # if locus_tag is moderately descriptive\n",
    "# # OR\n",
    "# features_name = [\"gene\", \"product\", \"description\", \"name\", \"note\", \"gene_synonym\", \"locus_tag\"] # if locus_tag is least descriptive\n",
    "#\n",
    "# CRITICAL: The regex variable name (after RE_) must exactly match the name\n",
    "# you add to features_name for the extraction to work properly\n",
    "\n",
    "re_features = {}\n",
    "for name in features_name:\n",
    "    try:\n",
    "        re_features[name] = globals()[f\"RE_{name}\"]\n",
    "    except KeyError:\n",
    "        print(f\"Warning: No regex found for '{name}' (expected variable: RE_{name})\")\n",
    "\n",
    "\n",
    "def increment_gdt_file(path):\n",
    "    \"\"\"\n",
    "    Increment the GDT file name by 1.\n",
    "    Example: fungi-ncbi_pilot_03.gdt -> fungi-ncbi_pilot_04.gdt\n",
    "    \"\"\"\n",
    "    plist = path.stem.split(\"_\")\n",
    "    if plist[-1] == \"stripped\":\n",
    "        plist[-1] = \"pilot\"\n",
    "        plist.append(0)\n",
    "\n",
    "    try:\n",
    "        number = int(plist[-1]) + 1\n",
    "        plist[-1] = f\"{number:02d}\"\n",
    "    except ValueError:\n",
    "        raise ValueError(\n",
    "            f\"Invalid GDT file name: {path.name}. Expected format: <preferred_name>_##.gdt, where ## is a number.\"\n",
    "        )\n",
    "    return path.parent / f'{\"_\".join(plist)}{path.suffix}', number\n",
    "\n",
    "\n",
    "def get_most_recent_gdt(dir_path, prefix=\"TEMP_\"):\n",
    "    \"\"\"\n",
    "    Get the most recent gdt file in the directory.\n",
    "    Arguments:\n",
    "        dir_path (Path): Directory to search for GDT files.\n",
    "        prefix (str): Prefix of the GDT files to search for. It will match files like \"<prefix>*.gdt\".\n",
    "    Returns:\n",
    "        Path: Path to the most recent GDT file.\n",
    "    \"\"\"\n",
    "    temp_files = list(\n",
    "        dir_path.glob(f\"*{prefix}*.gdt\")\n",
    "    )  # TODO maybe change to check for numbers after prefix?\n",
    "    if not temp_files:\n",
    "        return dir_path / f\"{prefix}00.gdt\"\n",
    "    return gdt.gdt_impl.natural_sort(temp_files, key=lambda x: x.stem)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines all the global variables used in the script.\n",
    "# Change these variables to match your local setup.\n",
    "# The most_recent_gdt_file variable should be set to the path of the most recent GDT file,\n",
    "# OR the stripped GDT file used in filter command, if applicable.\n",
    "\n",
    "DATA_DIR = \"../example/fungi_mt\"\n",
    "most_recent_gdt_filename = \"fungi_mt_pilot_06.gdt\"\n",
    "global_query_string = gdt.gff3_utils.QS_GENE_TRNA_RRNA\n",
    "remove_orfs = True\n",
    "gct = \"MIT\"\n",
    "gff_suffix = \".gff3\"\n",
    "\n",
    "print(f\"Chosen feature query string: '{global_query_string}'\")\n",
    "\n",
    "\n",
    "# just checking\n",
    "DATA_DIR = Path(DATA_DIR).resolve()\n",
    "if not DATA_DIR.is_dir():\n",
    "    raise FileNotFoundError(f\"Path {DATA_DIR} is not a directory.\")\n",
    "\n",
    "MISC_DIR = DATA_DIR / \"misc\"\n",
    "GDT_DIR = MISC_DIR / \"gdt\"\n",
    "GDT_DIR.mkdir(511, True, True)  # 511 = 0o777\n",
    "\n",
    "AN_missing_dbxref_GeneID = MISC_DIR / \"AN_missing_dbxref_GeneID.txt\"\n",
    "\n",
    "if not AN_missing_dbxref_GeneID.is_file():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Missing {AN_missing_dbxref_GeneID}, did you run gdt-cli filter?\"\n",
    "    )\n",
    "\n",
    "if \"most_recent_gdt_filename\" in globals():\n",
    "    gdt_path = GDT_DIR / most_recent_gdt_filename\n",
    "    if not gdt_path.is_file():\n",
    "        print(\n",
    "            f\"Not found {gdt_path.name}, does it exist in misc/gdt?\\nGDTs in {GDT_DIR}:\"\n",
    "        )\n",
    "        [print(f\" - {f.name}\") for f in sorted(GDT_DIR.glob(\"*.gdt\"))]\n",
    "        raise FileNotFoundError(\n",
    "            f\"Most recent GDT file {gdt_path.name} does not exist in {GDT_DIR}.\"\n",
    "        )\n",
    "else:\n",
    "    print(\n",
    "        \"Warning: 'most_recent_gdt_filename' variable not set.\\n\\n\"\n",
    "        \"You should have a GDT file from AN_missing_gene_dict.ipynb:\\n\"\n",
    "        \"• Set the most_recent_gdt_filename variable\\n\"\n",
    "        \"• Re-run this cell\\n\\n\"\n",
    "        \"If you intend to run this without a GDT file (e.g., because your GFF files \"\n",
    "        \"don't have dbxrefs and AN_missing_dbxref_GeneID.ipynb isn't needed), this warning can be ignored.\"\n",
    "    )\n",
    "    # to simplify the code, a exetution without most_recent_gdt_filename is\n",
    "    # basically the same as with one, but with and empty gdt file\n",
    "    gdt_path = GDT_DIR / \"pilot_00.gdt\"\n",
    "    gdt.gdt_impl.create_empty_gdt(gdt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddbed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = MISC_DIR / \"01_missing_dbxref_GeneID.log\"\n",
    "\n",
    "log = gdt.logger_setup.create_simple_logger(\n",
    "    print_to_console=True,\n",
    "    console_level=\"DEBUG\",\n",
    "    save_to_file=True,\n",
    "    file_level=\"TRACE\",\n",
    "    log_file=log_file,\n",
    ")\n",
    "log.debug(\"Running from notebook AN_missing_dbxref_GeneID.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d985e87",
   "metadata": {},
   "source": [
    "### Deeper investigation using other gff attributes, primarily gene="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a53d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(AN_missing_dbxref_GeneID, \"r\") as f:\n",
    "    ANs = [line.strip() for line in f.readlines() if line.strip()]\n",
    "log.info(f\"Found {len(ANs)} ANs in {AN_missing_dbxref_GeneID}\")\n",
    "log.trace(f\"ANs: {ANs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f3d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GDT file (even if empty)\n",
    "gene_dict = gdt.gdt_impl.create_gene_dict(gdt_path, max_an_sources=0)\n",
    "log.info(f\"GeneDict loaded from {gdt_path.name}\")\n",
    "log.debug(f\"path: {gdt_path}\")\n",
    "\n",
    "log.info(\"Header:\")\n",
    "for x in gene_dict.header:\n",
    "    log.info(f\"\\t{x}\")\n",
    "\n",
    "log.info(\"GDT Info:\")\n",
    "for x in gene_dict.info:\n",
    "    log.info(f\"\\t{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "to_drop = [\"source\", \"type\", \"start\", \"end\", \"score\", \"strand\", \"phase\", \"attributes\"]\n",
    "\n",
    "for AN in ANs:\n",
    "    an_path = DATA_DIR / f\"{AN}{gff_suffix}\"\n",
    "    df = gdt.gff3_utils.load_gff3(\n",
    "        an_path, query_string=global_query_string, usecols=gdt.GFF3_COLUMNS\n",
    "    )\n",
    "    df = gdt.gff3_utils.filter_orfs(df) if remove_orfs else df\n",
    "\n",
    "    df[\"gene_id\"] = df[\"attributes\"].str.extract(RE_ID, expand=False)\n",
    "    df = df[~df[\"gene_id\"].isin(gene_dict)]\n",
    "\n",
    "    # Procedually extract features based on the regex patterns defined\n",
    "    for name, pattern in re_features.items():\n",
    "        df[name] = df[\"attributes\"].str.extract(pattern, expand=False)\n",
    "\n",
    "    if df[features_name].isna().all(axis=1).any():\n",
    "        log.warning(f\"{AN} has row(s) with no identifiable atribute.\")\n",
    "        log.warning(\n",
    "            \"Please modify this script to add a new possible identifiable attribute or just remove the AN from your dataset\"\n",
    "        )\n",
    "        log.debug(df[df[features_name].isna().all(axis=1)])\n",
    "\n",
    "    temp_list.extend(df.to_dict(\"records\"))\n",
    "\n",
    "features_info_df = pd.DataFrame(temp_list)\n",
    "features_info_df = features_info_df.drop(columns=to_drop, errors=\"ignore\")\n",
    "\n",
    "drop_cols = [col for col in features_name if features_info_df[col].isna().all()]\n",
    "\n",
    "# Procedurally fill 'best_feature' based on the order of features_name\n",
    "features_info_df[\"best_feature\"] = features_info_df[features_name[0]]\n",
    "for col in features_name[1:]:\n",
    "    features_info_df[\"best_feature\"] = features_info_df[\"best_feature\"].fillna(\n",
    "        features_info_df[col]\n",
    "    )\n",
    "\n",
    "features_info_df = features_info_df.drop(columns=drop_cols)\n",
    "features_info_df = features_info_df.sort_values(by=\"best_feature\")\n",
    "log.debug(f\"Features info df, writing to {MISC_DIR / 'features_info.tsv'}\")\n",
    "features_info_df.to_csv(MISC_DIR / \"features_info.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3ed357",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_gdt_compliance = True\n",
    "comment = \"Manual from missing_dbxref_GeneID feature names\"\n",
    "\n",
    "if add_gdt_compliance:\n",
    "    gdt_str = f' #gd MANUAL{ \" #c \" + comment if comment else \"\" }'\n",
    "else:\n",
    "    gdt_str = \"\"\n",
    "\n",
    "# df with 2 columns, one for feature_names and one for in_gene_dict\n",
    "new_df = pd.DataFrame({\"best_feature\": features_info_df[\"best_feature\"].unique()})\n",
    "new_df[\"in_gene_dict\"] = new_df[\"best_feature\"].isin(gene_dict)\n",
    "\n",
    "unique_names = new_df[~new_df[\"in_gene_dict\"]][\"best_feature\"]\n",
    "unique_names = gdt.gdt_impl.natural_sort(unique_names)\n",
    "with open(MISC_DIR / \"feature_names.txt\", \"w+\") as f1:\n",
    "    for name in unique_names:\n",
    "        f1.write(f\"{name}{gdt_str}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d13888a",
   "metadata": {},
   "source": [
    "The user must now parse feature_names.txt  \n",
    "\n",
    "Features that can be easily identifiable must be added to the current  \n",
    "version of the gdt, and features that need deeper investigation should be  \n",
    "copied to a new file name 'feature_unks.txt'\n",
    "  \n",
    "The script will now try to automatically add the gene_ids with feature names   \n",
    "that __are not in 'feature_unks.txt'__ to gene_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6dd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the names exist in the gene_dict\n",
    "features_info_df = pd.read_csv(MISC_DIR / \"features_info.tsv\", sep=\"\\t\")\n",
    "\n",
    "names_unk = set()\n",
    "with open(MISC_DIR / \"feature_unks.txt\", \"r\") as f1:\n",
    "    for line in f1:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        if \"#gd\" in line:\n",
    "            line = line.split(\"#gd\")[0].strip()\n",
    "\n",
    "        names_unk.add(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef05f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\"Verifing that all feature_names.txt values (excluding those in feature_unks.txt) exist in the most_recent_gdt_filename.\")\n",
    "gene_dict = gdt.gdt_impl.create_gene_dict(gdt_path, max_an_sources=0)\n",
    "log.info(f\"GeneDict loaded from {gdt_path.name}\")\n",
    "log.debug(f\"path: {gdt_path}\")\n",
    "\n",
    "log.info(\"Header:\")\n",
    "for x in gene_dict.header:\n",
    "    log.info(f\"\\t{x}\")\n",
    "\n",
    "log.info(\"GDT Info:\")\n",
    "for x in gene_dict.info:\n",
    "    log.info(f\"\\t{x}\")\n",
    "\n",
    "names_not_in_dict = set()\n",
    "all_names = set(features_info_df[\"best_feature\"].unique()) - names_unk\n",
    "for name in all_names:\n",
    "    if name not in gene_dict:\n",
    "        names_not_in_dict.add(name)\n",
    "\n",
    "if names_not_in_dict:\n",
    "    log.debug(f\"Warning: {len(names_not_in_dict)} name(s) not in most_recent_gdt_filename!\")\n",
    "    log.debug(\n",
    "        \"These names are not in feature_unk, so you marked them as identifiable. Please identify them or add them feature_unk.\"\n",
    "    )\n",
    "    log.debug(\n",
    "        \"It could also be that you forgot to update and/or reload the most_recent_gdt_filename with the changes you made above.\"\n",
    "    )\n",
    "    [log.debug(name) for name in names_not_in_dict]\n",
    "    raise ValueError(f\"Error: {len(names_not_in_dict)} names not in most_recent_gdt_filename!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e914f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \"automated insertion from missing_dbxref_GeneID best feature\"\n",
    "unique_gene_ids = features_info_df[~features_info_df[\"best_feature\"].isin(names_unk)][\n",
    "    \"gene_id\"\n",
    "].unique()\n",
    "\n",
    "log.info(\" ---- [Starting 'Automated insertion of gene_ids with known features from features_info.tsv'] ----\")\n",
    "for gene_id in unique_gene_ids:\n",
    "    df = features_info_df[features_info_df[\"gene_id\"] == gene_id]\n",
    "\n",
    "    # sanity check, are all feature_names the same?\n",
    "    if df[\"best_feature\"].nunique() != 1:\n",
    "        log.warning(\n",
    "            f\"{gene_id} has multiple best_features: {df['best_feature'].unique()}\"\n",
    "        )\n",
    "        log.debug(\"\\tChecking if they have the same label in gene_dict...\")\n",
    "\n",
    "        labels = {gene_dict[feat].label for feat in df[\"best_feature\"].unique()}\n",
    "        if len(labels) != 1:\n",
    "            log.error(f\"\\tError: {gene_id} has multiple labels: {labels}\")\n",
    "            raise ValueError(\n",
    "                f\"Error: {gene_id} has multiple labels: {labels}. \"\n",
    "                \"Please edit features_info.tsv to resolve this issue.\"\n",
    "            )\n",
    "        else:\n",
    "            log.debug(f\"\\tAll best_features have the same label: {labels.pop()}\")\n",
    "\n",
    "    label = gene_dict[df[\"best_feature\"].iloc[0]].label\n",
    "    an_sources = df[\"seqid\"].unique().tolist()\n",
    "    log.debug(\n",
    "        f\"Adding {gene_id} with label '{label}', an_sources: {an_sources}, comment: {comment}\"\n",
    "    )\n",
    "    gene_dict[gene_id] = gdt.gdt_impl.GeneGeneric(\n",
    "        label=label, an_sources=an_sources, c=comment\n",
    "    )\n",
    "log.info(\" ---- [Finished 'Automated insertion of gene_ids with known features from features_info.tsv'] ----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82329a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path, nth_iteration = increment_gdt_file(gdt_path)\n",
    "log.info(f\"Writing gene_dict file: {new_path} | Iteration: {nth_iteration}\")\n",
    "gene_dict.info = gdt.gdt_impl.get_gene_dict_info(gene_dict)\n",
    "gene_dict.header.append(\n",
    "    f\"{datetime.now().strftime('%Y-%m-%d %H:%M')} - Data added from 'Automated insertion of gene_ids with known features from features_info.tsv'\"\n",
    ")\n",
    "gdt.gdt_impl.write_gdt_file(gene_dict, new_path, overwrite=True)\n",
    "log.info(f\"{new_path.name} was created in misc/gdt!\")\n",
    "log.info(\"You must now add it to most_recent_gdt_filename in the Setup cell, and rerun the cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350d5c33",
   "metadata": {},
   "source": [
    "#### TEMP Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2876441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the new GDT file is the most recent one in the setup cell!\n",
    "# Otherwise you will create a new gdt file without the previous changes.\n",
    "\n",
    "# TODO CRITIAL HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e4d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_dict = gdt.gdt_impl.create_gene_dict(gdt_path, max_an_sources=0)\n",
    "log.info(f\"GeneDict loaded from {gdt_path.name}\")\n",
    "log.debug(f\"path: {gdt_path}\")\n",
    "\n",
    "log.info(\"Header:\")\n",
    "for x in gene_dict.header:\n",
    "    log.info(f\"\\t{x}\")\n",
    "\n",
    "log.info(\"GDT Info:\")\n",
    "for x in gene_dict.info:\n",
    "    log.info(f\"\\t{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2083e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_unk = set()\n",
    "with open(MISC_DIR / \"feature_unks.txt\", \"r\") as f1:\n",
    "    for line in f1:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        if \"#gd\" in line:\n",
    "            line = line.split(\"#gd\")[0].strip()\n",
    "\n",
    "        names_unk.add(line)\n",
    "\n",
    "features_info_df = pd.read_csv(MISC_DIR / \"features_info.tsv\", sep=\"\\t\")\n",
    "features_unk_df = (\n",
    "    features_info_df[features_info_df[\"best_feature\"].isin(names_unk)]\n",
    "    .copy()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "unk_dict = features_unk_df.groupby(\"seqid\")[\"gene_id\"].agg(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7969df",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_unk = gdt.gdt_impl.GeneDict()\n",
    "label_count = 0\n",
    "change_gene_dict = False\n",
    "log.debug(\n",
    "    \"missing_dbxref_GeneID: matching probable 'child feature + parent gene' pair (on the an original gff3, using all the features)\"\n",
    ")\n",
    "for an in unk_dict.keys():\n",
    "    gene_ids = unk_dict[an]\n",
    "    log.debug(f\"AN: {an}| gene_ids: {gene_ids}\")\n",
    "    an_path = DATA_DIR / f\"{an}{gff_suffix}\"\n",
    "\n",
    "    df = gdt.gff3_utils.load_gff3(an_path, usecols=gdt.GFF3_COLUMNS)\n",
    "    df = gdt.gff3_utils.filter_orfs(df) if remove_orfs else df\n",
    "\n",
    "    df[\"gene_id\"] = df[\"attributes\"].str.extract(RE_ID, expand=False)\n",
    "    df[\"parent\"] = df[\"attributes\"].str.extract(RE_parent, expand=False)\n",
    "\n",
    "    for name, pattern in re_features.items():\n",
    "        df[name] = df[\"attributes\"].str.extract(pattern, expand=False)\n",
    "\n",
    "    # Procedurally fill 'best_feature' based on the order of features_name\n",
    "    df[\"best_feature\"] = df[features_name[0]]\n",
    "    for col in features_name[1:]:\n",
    "        df[\"best_feature\"] = df[\"best_feature\"].fillna(df[col])\n",
    "\n",
    "    for gene_id in gene_ids:\n",
    "        candidates = df[df[\"parent\"] == gene_id]\n",
    "        log.debug(f\" gene_id: {gene_id} | {len(candidates) = }\")\n",
    "\n",
    "        # Handle case where no candidates found\n",
    "        if len(candidates) == 0:\n",
    "            log.debug(f\" no candidate with parent={gene_id} found\")\n",
    "            log.debug(\"  adding it to UNKNOWN label\\n\")\n",
    "            temp_unk[gene_id] = gdt.gdt_impl.GeneGeneric(\n",
    "                label=f\"{gct}-UNKNOWN\",\n",
    "                an_sources=[an],\n",
    "                c=f\"unknown gene_id from {an}{gff_suffix} | \"\n",
    "                f\"a: {df[df['gene_id'] == gene_id]['attributes'].iloc[0] if not df[df['gene_id'] == gene_id].empty else 'N/A'}\",\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Handle feature name conflicts\n",
    "        if candidates[\"best_feature\"].nunique() > 1:\n",
    "            log.debug(\n",
    "                \" more than one canditate found, but with best_feature conflict, chosing the first one.\"\n",
    "            )\n",
    "            log.debug(f\"  best_features: {candidates['best_feature'].unique()}\")\n",
    "\n",
    "        best_feature = candidates[\"best_feature\"].iloc[0]\n",
    "        log.debug(f\"  chosen best_feature: {best_feature}\")\n",
    "        [\n",
    "            log.debug(f\"\\tt: {x.type} | fn: {x.best_feature} | a: {x.attributes}\")\n",
    "            for x in candidates.itertuples()\n",
    "        ]\n",
    "\n",
    "        # Handle case where feature_name is in gene_dict\n",
    "        if best_feature in gene_dict:\n",
    "            change_gene_dict = True\n",
    "            label = gene_dict[best_feature].label\n",
    "            log.debug(f\"  best_feature in gene_dict, label: {label}\\n\")\n",
    "            gene_dict[gene_id] = gdt.gdt_impl.GeneGeneric(\n",
    "                label=label,\n",
    "                an_sources=[an],\n",
    "                c=f\"insertion from missing_dbxref_GeneID feature mapping, source: {best_feature} | type: {candidates['type'].iloc[0]}\",\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Handle case where feature_name is NOT in gene_dict\n",
    "        log.debug(f\"  best_feature not in gene_dict: {best_feature}\")\n",
    "        log.debug(\"  checking in temp_unk\")\n",
    "\n",
    "        if best_feature in temp_unk:\n",
    "            label = temp_unk[best_feature].label\n",
    "            log.debug(f\"  found in temp_unk, label: {label}\\n\")\n",
    "            gene_dict[gene_id] = gdt.gdt_impl.GeneGeneric(\n",
    "                label=label,\n",
    "                an_sources=[an],\n",
    "                c=f\"insertion from missing_dbxref_GeneID feature mapping, source: {best_feature} | type: {candidates['type'].iloc[0]}\",\n",
    "            )\n",
    "        else:\n",
    "            label_count += 1\n",
    "            label = f\"{gct}-TEMP-{label_count}\"\n",
    "            log.debug(f\"  not found in temp_unk, new label: {label}\\n\")\n",
    "            temp_unk[best_feature] = gdt.gdt_impl.GeneDescription(\n",
    "                label=label, source=\"MANUAL\", c=None\n",
    "            )\n",
    "\n",
    "            temp_unk[gene_id] = gdt.gdt_impl.GeneGeneric(\n",
    "                label=label,\n",
    "                an_sources=[an],\n",
    "                c=f\"insertion from missing_dbxref_GeneID feature mapping, source: {best_feature} | type: {candidates['type'].iloc[0]}\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a790c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "if temp_unk:\n",
    "    temp_path = get_most_recent_gdt(GDT_DIR, prefix=\"TEMP_Mapping_\")\n",
    "    new_path, map_iteration = increment_gdt_file(temp_path)\n",
    "    log.info(f\"Writing TEMP Mapping GDT file: {new_path} | Iteration: {map_iteration}\")\n",
    "    temp_unk.info = gdt.gdt_impl.get_gene_dict_info(temp_unk)\n",
    "    temp_unk.header = [\n",
    "        \"version 0.0.2\",\n",
    "        f\"TEMP Mapping - {map_iteration}\",\n",
    "        f\"{datetime.now().strftime('%Y-%m-%d %H:%M')} - TEMP Mapping child features to parent genes\",\n",
    "    ]\n",
    "    gdt.gdt_impl.write_gdt_file(temp_unk, new_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b38296",
   "metadata": {},
   "outputs": [],
   "source": [
    "if change_gene_dict:\n",
    "    log.debug(\"gene_dict changed, incrementing gdt file and writing it\")\n",
    "    gdt_path, _ = increment_gdt_file(gdt_path)\n",
    "    log.info(f\"Writing GDT file: {gdt_path}\")\n",
    "    gene_dict.info = gdt.gdt_impl.get_gene_dict_info(gene_dict)\n",
    "    gene_dict.header.append(\n",
    "        f\"{datetime.now().strftime('%Y-%m-%d %H:%M')} - Data added from TEMP Mapping\"\n",
    "    )\n",
    "    gdt.gdt_impl.write_gdt_file(gene_dict, gdt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857707e0",
   "metadata": {},
   "source": [
    "### Genes exclusion of to_remove_2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e57d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_string = \"discard-\"\n",
    "genes_to_remove = \"to_remove_2.txt\"\n",
    "\n",
    "remove_gene_ids = defaultdict(set)\n",
    "with open(MISC_DIR / genes_to_remove, \"r\") as f:\n",
    "    for line in f:\n",
    "        if (\n",
    "            not line.strip()\n",
    "            or line.startswith(\"#\")\n",
    "            or line.startswith(\"[\")\n",
    "            or \"#gd\" in line\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        gene_id, an = line.split(\"#c\", 1)[0].split(\"#gn\", 1)\n",
    "        remove_gene_ids[an.strip()].add(gene_id.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d1705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(f\"Removing {len(remove_gene_ids)} gene IDs from GFF files.\")\n",
    "for an in remove_gene_ids.keys():\n",
    "    log.trace(f\"Processing {an} for removal of gene IDs {remove_gene_ids[an]}\")\n",
    "    an_path = DATA_DIR / f\"{an}{gff_suffix}\"\n",
    "    with open(an_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    headers, index = [], 0\n",
    "    while lines[index].startswith(\"#\"):\n",
    "        headers.append(lines[index].strip())\n",
    "        index += 1\n",
    "\n",
    "    pattern = re.compile(\"|\".join([f\"ID={x};\" for x in remove_gene_ids[an]]))\n",
    "    log.trace(f\"Pattern for removal: {pattern.pattern}\")\n",
    "    contents = []\n",
    "\n",
    "    for line in lines[index:]:\n",
    "        if not (line := line.strip()):\n",
    "            continue\n",
    "        line = line.split(\"\\t\")\n",
    "\n",
    "        # line[2] is type, line[8] is attributes\n",
    "        if pattern.search(line[8]):\n",
    "            if append_string not in line[2]:\n",
    "                line[2] = append_string + line[2]\n",
    "\n",
    "        contents.append(\"\\t\".join(line))\n",
    "\n",
    "    with open(an_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(headers))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\".join(contents))\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "log.info(f\"Finished removing gene IDs from {len(remove_gene_ids)} GFF files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
