{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9664aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "import gdt\n",
    "\n",
    "from Bio import Entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d05f8d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nth_iteration = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines all the global variables used in the script.\n",
    "# Change these variables to match your local setup.\n",
    "# The most_recent_gdt_file variable should be set to the path of the most recent GDT file,\n",
    "# OR the stripped GDT file used in filter command, if applicable.\n",
    "\n",
    "DATA_DIR = \"../test/Test_group16\"\n",
    "AN_missing_dbxref = \"../test/Test_group16/AN_missing_dbxref\"\n",
    "#most_recent_gdt_file = \"../test/Test_group16/Test_group16.gdt\"\n",
    "remove_orfs = True\n",
    "organelle_type = \"MT\"\n",
    "gff_suffix = \".gff3\"\n",
    "\n",
    "Entrez.email = 'dupin@alunos.utfpr.edu.br'\n",
    "Entrez.api_key = 'b3abc1ac7ae9ac035af84ec1abf895878d09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca23d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recent_gdt_file = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37b27fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you set up a stripped GDT file, please set the path to it in the most_recent_gdt_file variable.\n",
      "Otherwise, ignore this message.\n"
     ]
    }
   ],
   "source": [
    "# Check if all variables exist\n",
    "DATA_DIR = Path(DATA_DIR).resolve()\n",
    "AN_missing_dbxref = Path(AN_missing_dbxref).resolve()\n",
    "\n",
    "if not DATA_DIR.exists() and not DATA_DIR.is_dir():\n",
    "    raise FileNotFoundError(f\"Data directory {DATA_DIR} does not exist or is not a directory.\")\n",
    "\n",
    "if not AN_missing_dbxref.exists() and not AN_missing_dbxref.is_file():\n",
    "    raise FileNotFoundError(f\"AN missing dbxref {AN_missing_dbxref} does not exist or is not a file.\")\n",
    "\n",
    "if not most_recent_gdt_file:\n",
    "    if nth_iteration > 1:\n",
    "        raise FileNotFoundError(f\"Most recent GDT file {most_recent_gdt_file} does not exist or is not a file.\")\n",
    "    else:\n",
    "        print(f\"If you set up a stripped GDT file, please set the path to it in the most_recent_gdt_file variable.\")\n",
    "        print(f\"Otherwise, ignore this message.\")\n",
    "else:\n",
    "    most_recent_gdt_file = Path(most_recent_gdt_file).resolve()\n",
    "    if not most_recent_gdt_file.exists() and not most_recent_gdt_file.is_file():\n",
    "        raise FileNotFoundError(f\"Most recent GDT file {most_recent_gdt_file} does not exist or is not a file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ddbed68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 16:08:43,154 - DEBUG - Logger setup complete. Logging to /home/brenodupin/matheus/gdt/test/Test_group16/0_test_2.log\n",
      "2025-05-21 16:08:43,158 - DEBUG - Running from notebook AN_missing_dbxref\n"
     ]
    }
   ],
   "source": [
    "_, logger = gdt.logger_setup.logger_creater(log_file=DATA_DIR / '0_test_2.log', console_level=\"DEBUG\", file_level=\"TRACE\")\n",
    "logger.debug(\"Running from notebook AN_missing_dbxref\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15a53d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ANs): 118\n"
     ]
    }
   ],
   "source": [
    "with open(AN_missing_dbxref, \"r\") as f:\n",
    "    ANs = [line.strip() for line in f.readlines() if line.strip()]\n",
    "print(f\"len(ANs): {len(ANs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba5f282",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dbxref_path = DATA_DIR / \"missing_dbxref\"\n",
    "missing_dbxref_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0f3d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GDT file\n",
    "if most_recent_gdt_file:\n",
    "    gene_dict = gdt.gene_dict.create_gene_dict(most_recent_gdt_file, max_an_sources=0)\n",
    "else:\n",
    "    gene_dict = {}\n",
    "\n",
    "temp_gene_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11fbe452",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "for AN in ANs:\n",
    "    an_path = DATA_DIR / f'{AN}{gff_suffix}'\n",
    "    if not an_path.exists():\n",
    "        logger.error(f'Error: {AN} does not exist (an_path: {an_path})')\n",
    "        continue\n",
    "    \n",
    "    df = gdt.gff3_utils.load_gff3(an_path, query_string='type == \"gene\"', usecols=['seqid', 'start', 'end', 'type', 'attributes'])\n",
    "    df = gdt.gff3_utils.filter_orfs(df) if remove_orfs else df\n",
    "\n",
    "    df['gene_id'] = df['attributes'].str.split(';').str[0].str.replace('ID=', '', regex=False)\n",
    "    df['in_gene_dict'] = df['gene_id'].isin(gene_dict)\n",
    "    df_missing = df[~df['in_gene_dict']].copy()\n",
    "\n",
    "    temp_list.extend(df_missing[['gene_id', 'seqid']].to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c56ce2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dbxref = (pd.DataFrame(temp_list).groupby('gene_id')['seqid']\n",
    "                .agg(list)\n",
    "                .sort_index())  # Sort by gene_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e36b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write here anything you want to add to the missing_dbxref file, or leave it empty\n",
    "comment = \"manual insertion from missing_dbxref_compiled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80463db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(missing_dbxref_path / 'missing_dbxref_compiled.txt', 'w+') as f1:\n",
    "    for gene_id, seqid in agg_dbxref.items():\n",
    "        f1.write(f'{gene_id} #gn {\" \".join(seqid)}{ \" #c \" + comment if comment else \"\" }\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c942a16",
   "metadata": {},
   "source": [
    "After manual parsing of missing_dbxref_compiled.txt,  \n",
    "create missing_dbxref_problems.txt, with names that  \n",
    "are not readily indentifiable or that need deeper investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d985e87",
   "metadata": {},
   "source": [
    "### Deeper investigation using other gff attributes, primarily 'Name='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2bbf3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_with_no_dbxref = set()\n",
    "with open(missing_dbxref_path / 'missing_dbxref_problems.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('#') or not line.strip():\n",
    "            continue\n",
    "        # Get ANs part (after '||') and split into individual ANs\n",
    "        if '#c' in line:\n",
    "            line = line.split('#c')[0].strip()\n",
    "        \n",
    "        ans = line.split('#gn')[1].strip().split()\n",
    "        # Add each AN to the set\n",
    "        an_with_no_dbxref.update(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0d6ec37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AP012272.1', 'LC659289.1', 'MH725795.1'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "an_with_no_dbxref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4c3d1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "for AN in an_with_no_dbxref:\n",
    "    an_path = DATA_DIR / f'{AN}{gff_suffix}'\n",
    "    df = gdt.gff3_utils.load_gff3(an_path, query_string='type == \"gene\"', usecols=gdt.GFF3_COLUMNS) # TODO change query_string!\n",
    "    df = gdt.gff3_utils.filter_orfs(df) if remove_orfs else df\n",
    "\n",
    "\n",
    "    df['gene_id'] = df['attributes'].str[3:].str.partition(';', expand=False).str[0]\n",
    "    df = df[~df['gene_id'].isin(gene_dict)]\n",
    "    \n",
    "    df['source_gid'] = 'name'\n",
    "    df['name'] = df['attributes'].str.extract(r'Name=([^;]*)(?:;|$)')\n",
    "\n",
    "    # if 'name' is NaN, try to extract 'description='\n",
    "    # change source to 'description' if 'description=' is found\n",
    "    df['source_gid'] = np.where(df['name'].isna(), 'description', df['source_gid'])\n",
    "    df['name'] = df['name'].fillna(df['attributes'].str.extract(r'description=([^;]*)(?:;|$)', expand=False))\n",
    "\n",
    "    # if 'name' is still NaN, print a warning\n",
    "    if df['name'].isna().any():\n",
    "        print(f'Warning: {AN} has NaN names')\n",
    "        df['source_gid'] = np.where(df['name'].isna(), 'gene_synonym', df['source_gid'])\n",
    "        df['name'] = df['name'].fillna(df['attributes'].str.extract(r'gene_synonym=([^;]*)(?:;|$)', expand=False))\n",
    "\n",
    "        df['source_gid'] = np.where(df['name'].isna(), 'stil_nan', df['source_gid'])\n",
    "        print(df[df['name'].isna()])\n",
    "\n",
    "    temp_list.extend(df[['name', 'gene_id', 'seqid', 'source_gid']].to_dict('records'))\n",
    "\n",
    "gene_ans_name_df = pd.DataFrame(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c191a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_gdt_compliance = True\n",
    "comment = 'Manual from missing_dbxref_names_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3ed357",
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_gdt_compliance:\n",
    "    gdt_str = f' #gd MANUAL{ \" #c \" + comment if comment else \"\" }'\n",
    "else:\n",
    "    gdt_str = \"\"\n",
    "    \n",
    "with open(missing_dbxref_path / 'missing_dbxref_names_raw.txt', 'w+') as f1:\n",
    "    for name in sorted(gene_ans_name_df['name'].unique()):\n",
    "        f1.write(f'{name}{gdt_str}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d13888a",
   "metadata": {},
   "source": [
    "The user must now parse missing_dbxref_names_raw.txt into two files:  \n",
    "missing_dbxref_names_clean.txt  \n",
    "missing_dbxref_names_unk.txt  \n",
    "  \n",
    "missing_dbxref_names_clean.txt should contain all easily identifiable gene names,  \n",
    "all the names __must__ also be in your current GDT version, because the next step  \n",
    "will automaticaly add all gene_ids that have names inside missing_dbxref_names_clean.txt.  \n",
    "  \n",
    "missing_dbxref_names_unk.txt should contain all the names that you dont know or you're not certain about,  \n",
    "the next step for theses names are matching feature using CDS, then extracting information about these features,  \n",
    "to better classify the original gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6a6dd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_dbxref_names_clean.txt\n",
    "\n",
    "# Check if the names exist in the gene_dict\n",
    "names = set()\n",
    "with open(missing_dbxref_path / 'missing_dbxref_names_clean.txt', 'r') as f1:\n",
    "    for line in f1:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        if '#gd' in line:\n",
    "            line = line.split('#gd')[0].strip()\n",
    "        \n",
    "        names.add(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e914f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO check where is being read gene_dict\n",
    "for name in names:\n",
    "    if name not in gene_dict:\n",
    "        print(f\"W: {name} not in gene_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82329a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO automatically add the gene_id to the gene_dict that have a name in the missing_dbxref_names_clean.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a1d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_dbxref_names_unk.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9262ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df_rows(cds_trna):\n",
    "    for row_cds in cds_trna.itertuples():\n",
    "        print(f'\\ts: {row_cds.start}| e: {row_cds.end} | {row_cds.attributes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeb51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_gene_an = {}\n",
    "an_set = set()\n",
    "with open(f'{folder}_dbxref_names_unk.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        raw = line.strip().split('|')[1].strip()\n",
    "        gene_id, seqid = raw.split(' # ')\n",
    "        if ' ' in seqid:\n",
    "            seqid = [x.strip() for x in seqid.split()]\n",
    "        else:\n",
    "            seqid = [seqid.strip()]\n",
    "        gene_id = gene_id.strip()\n",
    "        \n",
    "        an_set.update(seqid)\n",
    "        temp_gene_an[gene_id] = seqid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c24e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_an_gene = {}\n",
    "for an in an_set:\n",
    "    for gene_id, seqid in temp_gene_an.items():\n",
    "        if an in seqid:\n",
    "            if an not in dict_an_gene:\n",
    "                dict_an_gene[an] = []\n",
    "            dict_an_gene[an].append(gene_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d637aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_an_gene\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
