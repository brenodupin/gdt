{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "446bdf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "import gdt\n",
    "\n",
    "from Bio import Entrez\n",
    "\n",
    "def increment_gdt_file(path: Path) -> tuple[Path, int]:\n",
    "    \"\"\"\n",
    "    Increment the GDT file name by 1.\n",
    "    Example: fungi-ncbi_pilot_03.gdt -> fungi-ncbi_pilot_04.gdt\n",
    "    \"\"\"\n",
    "    plist = path.stem.split(\"_\")\n",
    "    try:\n",
    "        number = int(plist[-1]) + 1\n",
    "        plist[-1] = f\"{number:02d}\"\n",
    "    except ValueError:\n",
    "        raise ValueError(\n",
    "            f\"Invalid GDT file name: {path.name}. Expected format: <preferred_name>_##.gdt, where ## is a number.\"\n",
    "        )\n",
    "    return path.parent / f'{\"_\".join(plist)}{path.suffix}', number\n",
    "\n",
    "def get_most_recent_gdt(dir_path: Path, prefix=\"TEMP_\") -> Path:\n",
    "    \"\"\"\n",
    "    Get the most recent gdt file in the directory.\n",
    "    Arguments:\n",
    "        dir_path (Path): Directory to search for GDT files.\n",
    "        prefix (str): Prefix of the GDT files to search for. It will match files like \"<prefix>*.gdt\".\n",
    "    Returns:\n",
    "        Path: Path to the most recent GDT file.\n",
    "    \"\"\"\n",
    "    temp_files = list(dir_path.glob(f\"{prefix}*.gdt\"))\n",
    "    if not temp_files:\n",
    "        return dir_path / f\"{prefix}00.gdt\"\n",
    "    return gdt.gene_dict_impl.natural_sort(temp_files, key=lambda x: x.stem)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "822b5b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines all the global variables used in the script.\n",
    "# Change these variables to match your local setup.\n",
    "# The most_recent_gdt_file variable should be set to the path of the most recent GDT file,\n",
    "# OR the stripped GDT file used in filter command, if applicable.\n",
    "\n",
    "DATA_DIR = \"../sandbox/algae_pt_test\"\n",
    "AN_missing_gene_dict = \"../sandbox/algae_pt_test/AN_missing_gene_dict\"\n",
    "most_recent_gdt_file = \"GDT_pilot_01.gdt\"\n",
    "remove_orfs = True\n",
    "organelle_type = \"PT\"\n",
    "gff_suffix = \".gff3\"\n",
    "\n",
    "Entrez.email = 'dupin@alunos.utfpr.edu.br'\n",
    "Entrez.api_key = 'b3abc1ac7ae9ac035af84ec1abf895878d09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9643a59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all variables exist\n",
    "DATA_DIR = Path(DATA_DIR).resolve()\n",
    "AN_missing_gene_dict = Path(AN_missing_gene_dict).resolve()\n",
    "\n",
    "if not DATA_DIR.exists() and not DATA_DIR.is_dir():\n",
    "    raise FileNotFoundError(f\"Data directory {DATA_DIR} does not exist or is not a directory.\")\n",
    "\n",
    "if not AN_missing_gene_dict.exists() and not AN_missing_gene_dict.is_file():\n",
    "    raise FileNotFoundError(f\"AN missing gene dictionary {AN_missing_gene_dict} does not exist or is not a file.\")\n",
    "\n",
    "MISC_DIR = DATA_DIR / \"misc\"\n",
    "MISC_DIR.mkdir(exist_ok=True)\n",
    "GDT_dir = MISC_DIR / \"gdt\"\n",
    "GDT_dir.mkdir(exist_ok=True)\n",
    "most_recent_gdt_file = GDT_dir / most_recent_gdt_file\n",
    "if not most_recent_gdt_file:\n",
    "        print(f\"If you set up a stripped GDT file, please set the path to it in the most_recent_gdt_file variable.\")\n",
    "        print(f\"Otherwise, ignore this message.\")\n",
    "else:\n",
    "    most_recent_gdt_file = Path(most_recent_gdt_file).resolve()\n",
    "    if not most_recent_gdt_file.exists() and not most_recent_gdt_file.is_file():\n",
    "        raise FileNotFoundError(f\"Most recent GDT file {most_recent_gdt_file} does not exist or is not a file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61084bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 15:04:57,404 - DEBUG - Logger setup complete. Logging to /home/brenodupin/matheus/gdt/sandbox/algae_pt_test/misc/01_test.log\n",
      "2025-05-30 15:04:57,416 - DEBUG - Running from notebook AN_missing_gene_dict\n"
     ]
    }
   ],
   "source": [
    "_, logger = gdt.logger_setup.logger_creater(log_file=MISC_DIR / \"01_test.log\", console_level=\"DEBUG\", file_level=\"TRACE\")\n",
    "logger.debug(\"Running from notebook AN_missing_gene_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e64a01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ANs): 176\n"
     ]
    }
   ],
   "source": [
    "with open(AN_missing_gene_dict, \"r\") as f:\n",
    "    ANs = [line.strip() for line in f.readlines() if line.strip()]\n",
    "print(f\"len(ANs): {len(ANs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0aaaf709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(df_missing, AN, gene_dict, temp_gene_dict,\n",
    "                 organelle_type, temp_count, logger, use_NCBI_symbol=False,\n",
    "                 use_gene=False, temp_name='temp_desc', c_text='ncbi_desc', gn_tag='NCBI'):\n",
    "    \"\"\"\n",
    "    Process the data in the dataframe and update the gene_dict and corresponding temp_gene_dict.\n",
    "    Args:\n",
    "        df_missing (pd.DataFrame): DataFrame containing the missing genes.\n",
    "        AN (str): The accession number.\n",
    "        gene_dict (dict): Dictionary containing gene information.\n",
    "        temp_gene_dict (dict): Temporary dictionary for gene information.\n",
    "        organelle_type (str): Type of organelle. Should be \"MT\" or \"PT\".\n",
    "        temp_count (int): Counter for temporary labels.\n",
    "        logger: Logger object for logging messages.\n",
    "        use_NCBI_symbol (bool): Flag to indicate whether to use NCBI gene symbol or NCBI description. Default is False, which means use NCBI description.\n",
    "        use_gene (bool): Flag to indicate whether to use gff gene or not. Default is False, which means use what was set with use_NCBI_symbol.\n",
    "        temp_name (str): Name for the temporary dictionary. Default is 'temp_desc'.\n",
    "    Returns:\n",
    "        tuple: Updated gene_dict, temp_gene_dict, and temp_count.\n",
    "    \"\"\"\n",
    "    for row in df_missing.itertuples():\n",
    "        check_var = row.gene_symbol if use_NCBI_symbol else row.desc\n",
    "        check_var = row.gene if use_gene else check_var\n",
    "        check_desc = f'{check_var} | ncbi_desc: {row.desc}' if use_NCBI_symbol else check_var\n",
    "\n",
    "        logger.debug(f'gene_id: {row.gene_id} | dbxref: {row.dbxref} | s: {row.start} | att: {row.attributes}')\n",
    "        logger.trace(f'\\tname: {row.other_aliases} | desc: {row.desc} | gene_symbol: {row.gene_symbol}')\n",
    "        logger.trace(f'\\tcheck_var: {check_var} | use_symbol: {use_NCBI_symbol} | use_gene: {use_gene}')        \n",
    "        \n",
    "        if check_var in gene_dict:\n",
    "            gene_label = gene_dict[check_var].label\n",
    "            logger.debug(f'\\t[1st T]Label in gene_dict, L: |{gene_label}| adding: {row.gene_id} #dx {AN}:{row.dbxref} #c {c_text}: {check_desc}')\n",
    "            gene_dict[row.gene_id] = gdt.gene_dict_impl.GeneDbxref(\n",
    "                    label=gene_label,\n",
    "                    an_source=AN,\n",
    "                    dbxref=row.dbxref,\n",
    "                    c=f'{c_text}: {check_desc}')\n",
    "        \n",
    "        else:\n",
    "            logger.trace(f'\\t[1st F]Label not found gene_dict | checking {temp_name} | Label: {check_var}')\n",
    "\n",
    "            if check_var in temp_gene_dict:\n",
    "                gene_label = temp_gene_dict[check_var].label\n",
    "                logger.debug(f'\\t[2nd T]Label in {temp_name}, L: |{gene_label}| adding: {row.gene_id} #dx {AN}:{row.dbxref} #c {c_text}: {check_desc}')\n",
    "                temp_gene_dict[row.gene_id] = gdt.gene_dict_impl.GeneDbxref(\n",
    "                    label=gene_label,\n",
    "                    an_source=AN,\n",
    "                    dbxref=row.dbxref,\n",
    "                    c=f'{c_text}: {check_desc}')\n",
    "            else:\n",
    "                \n",
    "                temp_count += 1\n",
    "                label = f'{organelle_type}-TEMP-{temp_count}'\n",
    "                logger.debug(f'\\t[2nd F]Label not in {temp_name}, new label |{label}| adding: {row.gene_id} #dx {AN}:{row.dbxref} #c {c_text}: {check_desc}')\n",
    "                temp_gene_dict[check_var] = gdt.gene_dict_impl.GeneDescription(\n",
    "                    label=label,\n",
    "                    source=gn_tag,\n",
    "                    c=None)\n",
    "\n",
    "                temp_gene_dict[row.gene_id] = gdt.gene_dict_impl.GeneDbxref(\n",
    "                    label=label,\n",
    "                    an_source=AN,\n",
    "                    dbxref=row.dbxref,\n",
    "                    c=f'{c_text}: {check_desc}')\n",
    "    \n",
    "    return gene_dict, temp_gene_dict, temp_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c671cc",
   "metadata": {},
   "source": [
    "### TEMP using NCBI description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b3ad533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded gene_dict from /home/brenodupin/matheus/gdt/sandbox/algae_pt_test/misc/gdt/GDT_pilot_01.gdt\n",
      "Header:\n",
      "version 0.0.2\n",
      "Green_Algae_pt\n",
      "2025-04-09 18:56 - Conversion from gdt to gdt2\n",
      "2025-05-28 16:24 - Stripped GDT version from original GDT file Green_Algae_pt.gdt\n",
      "Data added from TEMP 01\n",
      "\n",
      "GDT Info:\n",
      "Gene dictionary length: 26114\n",
      "Label: 247\n",
      "GeneDescription: 1702\n",
      "GeneGenerics: 0\n",
      "GeneDbxref: 24412\n"
     ]
    }
   ],
   "source": [
    "# Load the GDT file\n",
    "if most_recent_gdt_file:\n",
    "    gene_dict = gdt.gene_dict_impl.create_gene_dict(most_recent_gdt_file, max_an_sources=0)\n",
    "    print(f\"Loaded gene_dict from {most_recent_gdt_file}\\nHeader:\")\n",
    "    [print(x) for x in gene_dict['gdt_header']]\n",
    "    print(\"\\nGDT Info:\")\n",
    "    [print(x) for x in gene_dict['gdt_info']]\n",
    "else:\n",
    "    gene_dict = {}\n",
    "    print(\"No GDT file found, starting with an empty gene_dict.\")\n",
    "\n",
    "temp_gene_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f984083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_ID = re.compile(r'ID=([^;]+)')\n",
    "RE_GENE = re.compile(r'gene=([^;]+)')\n",
    "RE_DBXREF = re.compile(r'Dbxref=GeneID:([^;]+)')\n",
    "RE_DBXREF2 = re.compile(r'GeneID:([^;]+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_gene_dict = {}\n",
    "temp_count = 0\n",
    "errors = []\n",
    "logger.info(' ---- [Starting TEMP process] ----')\n",
    "for i, AN in enumerate(ANs):\n",
    "    logger.debug(f'-- [Processing: {AN}] --')\n",
    "    \n",
    "    an_path = DATA_DIR / f'{AN}{gff_suffix}'\n",
    "    if not an_path.exists():\n",
    "        logger.error(f'Error: {AN} does not exist (an_path: {an_path})')\n",
    "        errors.append((AN, 'File not found'))\n",
    "        continue\n",
    "    \n",
    "    df = gdt.gff3_utils.load_gff3(an_path, query_string=gdt.gff3_utils.QS_GENE_TRNA_RRNA)\n",
    "    df = gdt.gff3_utils.filter_orfs(df) if remove_orfs else df\n",
    "\n",
    "    # getting the gene_id and if it is in the gene_dict\n",
    "    df['gene_id'] = df['attributes'].str.extract(RE_ID, expand=False)\n",
    "    df['gene'] = df['attributes'].str.extract(RE_GENE, expand=False)\n",
    "    df['in_gene_dict'] = df['gene_id'].isin(gene_dict)\n",
    "    df['has_gene'] = df['gene'].notna()\n",
    "    \n",
    "    #placeholder for adding parent dbxref to child genes\n",
    "\n",
    "    df['dbxref'] = df['attributes'].str.extract(RE_DBXREF, expand=False)\n",
    "    #df['dbxref'] = df['dbxref'].fillna(df['attributes'].str.extract(RE_DBXREF2, expand=False))  # Fallback to gene_id if dbxref is NaN\n",
    "    # TODO, deal with multiple GeneID in dbxref\n",
    "    \n",
    "    df_missing = df[~df['in_gene_dict'] & ~df['has_gene']].copy()\n",
    "    df_gene = df[~df['in_gene_dict'] & df['has_gene']].copy()\n",
    "\n",
    "    if not df_gene.empty:\n",
    "        logger.debug(f'Found {len(df_gene)} genes in {AN} that are not in the gene_dict, but have a gene attribute.')\n",
    "        df_gene[['other_aliases', 'desc', 'gene_symbol']] = np.nan\n",
    "        gene_dict, temp_gene_dict, temp_count = data_process(\n",
    "            df_gene, AN, gene_dict, temp_gene_dict, organelle_type,\n",
    "            temp_count, logger, use_gene=True, temp_name='temp_gene', c_text='gff_gene', gn_tag='gff_gene')\n",
    "    else:\n",
    "        logger.debug(f'No genes found in {AN} that are not in the gene_dict, but have a gene attribute.')\n",
    "\n",
    "    if df_missing.empty:\n",
    "        logger.debug(f'No missing genes in {AN} that are not in the gene_dict and do not have a gene attribute.')\n",
    "        continue\n",
    "\n",
    "    # two step method to extract dbxref, first try to get the full dbxref,\n",
    "    # if not all genes are numeric and not NaN, fallback to GeneID,\n",
    "    # check again if all genes are numeric and not NaN.\n",
    "    # if not, raise an error\n",
    "    if df_missing['dbxref'].isna().any() or not df_missing['dbxref'].str.isnumeric().all():\n",
    "        logger.warning(f'Error in {AN} - dbxref is not numeric or contains NaN')\n",
    "        logger.debug('\\ttrying only \"GeneID:\"')\n",
    "        \n",
    "        df_missing['dbxref'] = df_missing['attributes'].str.extract(RE_DBXREF2, expand=False)\n",
    "        if not df_missing['dbxref'].str.isnumeric().all() or df_missing['dbxref'].isna().any():\n",
    "            logger.error(f'\\tError in {AN} - dbxref is not numeric or contains NaN x2')\n",
    "            errors.append((AN, 'NaN or not numeric'))\n",
    "            continue\n",
    "        else:\n",
    "            logger.debug('\\tSuccess! - continuing')\n",
    "\n",
    "    # search NCBI\n",
    "    with Entrez.esummary(db=\"gene\", id=\",\".join(df_missing['dbxref'])) as search_handle:\n",
    "        try:\n",
    "            search_results = Entrez.read(search_handle)['DocumentSummarySet']['DocumentSummary'] # type: ignore\n",
    "        except (RuntimeError, KeyError, Exception) as ex:\n",
    "            logger.error(f'{ex} in Entrez.read for {AN}')\n",
    "            errors.append((AN, 'Entrez.read'))\n",
    "            continue\n",
    "    \n",
    "    mr_check = len(df_missing) == len(search_results)\n",
    "    logger.trace(f\"\\tm: {len(df_missing)} | r: {len(search_results)} | m/r check: {mr_check}\") # type: ignore\n",
    "    \n",
    "    # merge with search_results\n",
    "    temp_df = pd.DataFrame([{\n",
    "        'dbxref': x.attributes['uid'],\n",
    "        'other_aliases': x.get('OtherAliases', 'no_other_aliases'),\n",
    "        'desc': x.get('Description', 'no_description'),\n",
    "        'gene_symbol': x.get('Name', 'no_gene_symbol')\n",
    "        } for x in search_results])\n",
    "    \n",
    "    df_missing = df_missing.merge(temp_df, on='dbxref', how='left', copy=False)\n",
    "\n",
    "    # check if df_missing len is equal to search_results, and equal to the original df\n",
    "    if (len(df_missing) != len(temp_df)) or (len(df_missing) != len(df[~df['in_gene_dict'] & ~df['has_gene']])):\n",
    "        logger.warning(f\"{AN} m/r check: {mr_check} | df_missing len {len(df_missing)} | temp_df len {len(temp_df)} | df len {len(df[~df['in_gene_dict'] & ~df['has_gene']])}\")\n",
    "        logger.warning(f'This is not expected, but can be caused by fragmented genes that have the same dbxref/gene_id. Please check the log file for more details in TRACE level.')\n",
    "\n",
    "    # process the data\n",
    "    gene_dict, temp_gene_dict, temp_count = data_process(df_missing, AN, gene_dict,\n",
    "                                                         temp_gene_dict, organelle_type,\n",
    "                                                         temp_count, logger)\n",
    "    \n",
    "\n",
    "logger.info(f' ---- [Finished] ----')\n",
    "if errors:\n",
    "    logger.warning(f'Errors: {len(errors)}')\n",
    "    for an, msg in errors:\n",
    "        logger.warning(f'{an} - {msg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc2b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if temp_gene_dict:\n",
    "    temp_path = get_most_recent_gdt(GDT_dir, prefix=\"TEMP_\")\n",
    "    new_path, nth_iteration = increment_gdt_file(temp_path)\n",
    "    logger.info(f'Writing TEMP GDT file: {new_path} | Iteration: {nth_iteration}')\n",
    "    temp_gene_dict['gdt_info'] = gdt.gene_dict_impl.get_gene_dict_info(temp_gene_dict)\n",
    "    temp_gene_dict['gdt_header'] = ['version 0.0.2', f'TEMP - {nth_iteration}', 'Automagically generated by AN_missing_gene_dict.ipynb | TEMP using NCBI gene description']\n",
    "    gdt.gene_dict_impl.write_gdt_file(temp_gene_dict, new_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363af008",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gene_dict:\n",
    "    new_path, nth_iteration = increment_gdt_file(most_recent_gdt_file)\n",
    "    logger.info(f'Writing TEMP GDT file: {new_path} | Iteration: {nth_iteration}')\n",
    "    gene_dict['gdt_info'] = gdt.gene_dict_impl.get_gene_dict_info(gene_dict)\n",
    "    gene_dict['gdt_header'].append(f'Data added from TEMP {nth_iteration:02}')\n",
    "    gdt.gene_dict_impl.write_gdt_file(gene_dict, new_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728db9b1",
   "metadata": {},
   "source": [
    "### TEMP using NCBI Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5c69f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANS_Symbol = set()\n",
    "\n",
    "with open(MISC_DIR / \"seed_TEMP_Symbol.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        \n",
    "        if not line or line.startswith('#') or line.startswith('[') or '#gd' in line:\n",
    "            continue\n",
    "\n",
    "        ANS_Symbol.add(line.split('#dx', 1)[1].strip().split(':', 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67b13680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you running this right after the TEMP process, you need to update most_recent_gdt_file\n",
    "# to the GDT_pilot file created in the TEMP process.\n",
    "most_recent_gdt_file = GDT_dir / f'GDT_pilot_{nth_iteration:02}.gdt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b4da521",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if most_recent_gdt_file:\n",
    "    gene_dict = gdt.gene_dict_impl.create_gene_dict(most_recent_gdt_file, max_an_sources=0)\n",
    "else:\n",
    "    gene_dict = {}\n",
    "\n",
    "temp_symbol_gene_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55886959",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_symbol_gene_dict = {}\n",
    "temp_count = 0\n",
    "errors = []\n",
    "logger.info(' ---- [Starting TEMP process] ----')\n",
    "for i, AN in enumerate(ANS_Symbol):\n",
    "    logger.debug(f'-- [Processing: {AN}] --')\n",
    "    \n",
    "    an_path = DATA_DIR / f'{AN}{gff_suffix}'\n",
    "    if not an_path.exists():\n",
    "        logger.error(f'Error: {AN} does not exist (an_path: {an_path})')\n",
    "        errors.append((AN, 'File not found'))\n",
    "        continue\n",
    "    \n",
    "    df = gdt.gff3_utils.load_gff3(an_path, query_string=gdt.gff3_utils.QS_GENE_TRNA_RRNA)\n",
    "    df = gdt.gff3_utils.filter_orfs(df) if remove_orfs else df\n",
    "\n",
    "    # getting the gene_id and if it is in the gene_dict\n",
    "    df['gene_id'] = df['attributes'].str.extract(RE_ID, expand=False)\n",
    "    df['in_gene_dict'] = df['gene_id'].isin(gene_dict)\n",
    "    df_missing = df[~df['in_gene_dict']].copy()\n",
    "\n",
    "    # two step method to extract dbxref, first try to get the full dbxref,\n",
    "    # if not all genes are numeric and not NaN, fallback to GeneID,\n",
    "    # check again if all genes are numeric and not NaN.\n",
    "    # if not, raise an error\n",
    "    df_missing['dbxref'] = df_missing['attributes'].str.extract(RE_DBXREF, expand=False)\n",
    "    if df_missing['dbxref'].isna().any() or not df_missing['dbxref'].str.isnumeric().all():\n",
    "        logger.warning(f'Error in {AN} - dbxref is not numeric or contains NaN')\n",
    "        logger.debug('\\ttrying only \"GeneID:\"')\n",
    "        \n",
    "        df_missing['dbxref'] = df_missing['attributes'].str.extract(RE_DBXREF2, expand=False)\n",
    "        if not df_missing['dbxref'].str.isnumeric().all() or df_missing['dbxref'].isna().any():\n",
    "            logger.error(f'\\tError in {AN} - dbxref is not numeric or contains NaN x2')\n",
    "            errors.append((AN, 'NaN or not numeric'))\n",
    "            continue\n",
    "        else:\n",
    "            logger.debug('\\tSuccess! - continuing')\n",
    "\n",
    "    # search NCBI\n",
    "    with Entrez.esummary(db=\"gene\", id=\",\".join(df_missing['dbxref'])) as search_handle:\n",
    "        try:\n",
    "            search_results = Entrez.read(search_handle)['DocumentSummarySet']['DocumentSummary'] # type: ignore\n",
    "        except (RuntimeError, KeyError, Exception) as ex:\n",
    "            logger.error(f'{ex} in Entrez.read for {AN}')\n",
    "            errors.append((AN, 'Entrez.read'))\n",
    "            continue\n",
    "    \n",
    "    mr_check = len(df_missing) == len(search_results)\n",
    "    logger.trace(f\"\\tm: {len(df_missing)} | r: {len(search_results)} | m/r check: {mr_check}\") # type: ignore\n",
    "    \n",
    "    # merge with search_results\n",
    "    temp_df = pd.DataFrame([{\n",
    "        'dbxref': x.attributes['uid'],\n",
    "        'other_aliases': x.get('OtherAliases', 'no_other_aliases'),\n",
    "        'desc': x.get('Description', 'no_description'),\n",
    "        'gene_symbol': x.get('Name', 'no_gene_symbol')\n",
    "        } for x in search_results])\n",
    "    \n",
    "    df_missing = df_missing.merge(temp_df, on='dbxref', how='left', copy=False)\n",
    "\n",
    "    # check if df_missing len is equal to search_results, and equal to the original df\n",
    "    if (len(df_missing) != len(temp_df)) or (len(df_missing) != len(df[~df['in_gene_dict']])):\n",
    "        logger.warning(f'{AN} m/r check: {mr_check} | df_missing len {len(df_missing)} | temp_df len {len(temp_df)} | df len {len(df[~df[\"in_gene_dict\"]])}')\n",
    "        logger.warning(f'This is not expected, but can be caused by fragmented genes that have the same dbxref/gene_id. Please check the log file for more details in TRACE level.')\n",
    "    \n",
    "    # process the data\n",
    "    gene_dict, temp_symbol_gene_dict, temp_count = data_process(df_missing, AN, gene_dict,\n",
    "                                                         temp_symbol_gene_dict, organelle_type,\n",
    "                                                         temp_count, logger, temp_name='temp_symbol',\n",
    "                                                         use_NCBI_symbol=True, c_text='ncbi_symbol')\n",
    "    \n",
    "\n",
    "logger.info(f' ---- [Finished] ----')\n",
    "if errors:\n",
    "    logger.warning(f'Errors: {len(errors)}')\n",
    "    for an, msg in errors:\n",
    "        logger.warning(f'{an} - {msg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2a7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if temp_symbol_gene_dict:\n",
    "    temp_path = get_most_recent_gdt(GDT_dir, prefix=\"TEMP_Symbol_\")\n",
    "    new_path, nth_iteration = increment_gdt_file(temp_path)\n",
    "    logger.info(f'Writing TEMP Symbol GDT file: {new_path} | Iteration: {nth_iteration}')\n",
    "    temp_symbol_gene_dict['gdt_info'] = gdt.gene_dict_impl.get_gene_dict_info(temp_symbol_gene_dict)\n",
    "    temp_symbol_gene_dict['gdt_header'] = ['version 0.0.2', f'TEMP Symbol - {nth_iteration}', 'Automagically generated by AN_missing_gene_dict.ipynb | TEMP Symbol using NCBI gene symbol']\n",
    "    gdt.gene_dict_impl.write_gdt_file(temp_symbol_gene_dict, new_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5d9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gene_dict:\n",
    "    new_path, nth_iteration = increment_gdt_file(most_recent_gdt_file)\n",
    "    logger.info(f'Writing TEMP GDT file: {new_path} | Iteration: {nth_iteration}')\n",
    "    gene_dict['gdt_info'] = gdt.gene_dict_impl.get_gene_dict_info(gene_dict)\n",
    "    gene_dict['gdt_header'].append(f'Data added from TEMP {nth_iteration:02}')\n",
    "    gdt.gene_dict_impl.write_gdt_file(gene_dict, new_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d69fe05",
   "metadata": {},
   "source": [
    "### Genes Discard using dbxref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b38d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_string = 'discard-'\n",
    "genes_to_remove = \"gene_to_remove\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bcb6c5",
   "metadata": {},
   "source": [
    "gene-J2C28_mgp19 #dx NC_053825.1:63373456 #c ncbi_desc: hypothetical protein\n",
    "gene-J2C28_mgp16 #dx NC_053825.1:63373460 #c ncbi_desc: hypothetical protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1c6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dbxref = {}\n",
    "with open(genes_to_remove, \"r\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        \n",
    "        an, dbxref = line.split(\"#c\", 1)[0].split(\"#dx\", 1)[1].strip().split(\":\")\n",
    "        \n",
    "        if not an or not dbxref:\n",
    "            raise ValueError(f\"Error: {line} - AN and dbxref are empty after split, why?\")\n",
    "        \n",
    "        if an not in remove_dbxref:\n",
    "            remove_dbxref[an] = [dbxref]\n",
    "        else:\n",
    "            remove_dbxref[an].append(dbxref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea14e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dbxref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17773f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for an in remove_dbxref.keys():\n",
    "    an_path = DATA_DIR / f'{an}{gff_suffix}'\n",
    "    with open(an_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    headers, index = [], 0\n",
    "    while lines[index].startswith('#'):\n",
    "        headers.append(lines[index].strip())\n",
    "        index += 1\n",
    "\n",
    "    pattern = re.compile('|'.join([f'GeneID:{x}[,;]' for x in remove_dbxref[an]]))\n",
    "    contents = []\n",
    "\n",
    "    for line in lines[index:]:\n",
    "        if not (line := line.strip()): continue\n",
    "        line = line.split('\\t')\n",
    "        \n",
    "        if pattern.search(line[8]):\n",
    "            if 'discard-' not in line[2]:\n",
    "                line[2] = remove_string + line[2]\n",
    "        \n",
    "        contents.append('\\t'.join(line))\n",
    "    \n",
    "    with open(an_path, 'w') as f:\n",
    "        f.write('\\n'.join(headers))\n",
    "        f.write('\\n')\n",
    "        f.write('\\n'.join(contents))\n",
    "        f.write('\\n\\n')\n",
    "\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3196a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdt.write_gdt_file_sorted(gene_dict, GDT_dir / f'pilot_01_sorted.gdt', overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
