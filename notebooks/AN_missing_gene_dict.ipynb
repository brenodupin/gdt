{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446bdf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and functions\n",
    "import re\n",
    "import gdt\n",
    "import pandas as pd\n",
    "from Bio import Entrez\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "RE_ID = re.compile(r\"ID=([^;]+)\")\n",
    "RE_gene = re.compile(r\"gene=([^;]+)\")\n",
    "RE_dbxref = re.compile(r\"Dbxref=GeneID:([^;,]+)\")\n",
    "# RE_dbxref = re.compile(r\"GeneID:([^;,]+)\")\n",
    "\n",
    "# todo talk about the dbxref2\n",
    "\n",
    "\n",
    "def increment_gdt_file(path):\n",
    "    \"\"\"\n",
    "    Increment the GDT file name by 1.\n",
    "    Example: fungi-ncbi_pilot_03.gdt -> fungi-ncbi_pilot_04.gdt\n",
    "    \"\"\"\n",
    "    plist = path.stem.split(\"_\")\n",
    "    if plist[-1] == \"stripped\":\n",
    "        plist[-1] = \"pilot\"\n",
    "        plist.append(0)\n",
    "\n",
    "    try:\n",
    "        number = int(plist[-1]) + 1\n",
    "        plist[-1] = f\"{number:02d}\"\n",
    "    except ValueError:\n",
    "        raise ValueError(\n",
    "            f\"Invalid GDT file name: {path.name}. Expected format: <preferred_name>_##.gdt, where ## is a number.\"\n",
    "        )\n",
    "    return path.parent / f'{\"_\".join(plist)}{path.suffix}', number\n",
    "\n",
    "\n",
    "def get_most_recent_gdt(dir_path, prefix=\"TEMP_\"):\n",
    "    \"\"\"\n",
    "    Get the most recent gdt file in the directory.\n",
    "    Arguments:\n",
    "        dir_path (Path): Directory to search for GDT files.\n",
    "        prefix (str): Prefix of the GDT files to search for. It will match files like \"<prefix>*.gdt\".\n",
    "    Returns:\n",
    "        Path: Path to the most recent GDT file.\n",
    "    \"\"\"\n",
    "    temp_files = list(dir_path.glob(f\"*{prefix}*.gdt\"))\n",
    "    if not temp_files:\n",
    "        return dir_path / f\"{prefix}00.gdt\"\n",
    "    return gdt.gene_dict_impl.natural_sort(temp_files, key=lambda x: x.stem)[-1]\n",
    "\n",
    "\n",
    "def data_process(\n",
    "    df_missing,\n",
    "    AN,\n",
    "    gene_dict,\n",
    "    temp_gene_dict,\n",
    "    organelle_type,\n",
    "    temp_count,\n",
    "    log,\n",
    "    use_NCBI_symbol=False,\n",
    "    use_gene=False,\n",
    "    temp_name=\"temp_desc\",\n",
    "    c_text=\"ncbi_desc\",\n",
    "    gn_tag=\"NCBI\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Process the data in the dataframe and update the gene_dict and corresponding temp_gene_dict.\n",
    "    Args:\n",
    "        df_missing (pd.DataFrame): DataFrame containing missing gene information.\n",
    "        AN (str): Annotation source identifier.\n",
    "        gene_dict (dict): Dictionary to store gene information.\n",
    "        temp_gene_dict (dict): Temporary dictionary for gene descriptions.\n",
    "        organelle_type (str): Type of organelle, MT or PT.\n",
    "        temp_count (int): Counter for temporary labels.\n",
    "        log (Logger): Logger instance for logging debug information.\n",
    "        use_NCBI_symbol (bool): Whether to use NCBI gene symbols. Default is False, so it uses gene descriptions.\n",
    "        use_gene (bool): Whether to use the 'gene' field instead of NCBI information.\n",
    "        temp_name (str): Name for the temporary dictionary.\n",
    "        c_text (str): Text to be used in the '#c' field of the GeneDbxref object.\n",
    "        gn_tag (str): Tag for the source of the gene description.\n",
    "    Returns:\n",
    "        tuple: Updated gene_dict, temp_gene_dict, and temp_count.\n",
    "    \"\"\"\n",
    "    for row in df_missing.itertuples():\n",
    "        check_var = row.gene_symbol if use_NCBI_symbol else row.desc\n",
    "        check_var = row.gene if use_gene else check_var\n",
    "        check_desc = (\n",
    "            f\"{check_var} | ncbi_desc: {row.desc}\" if use_NCBI_symbol else check_var\n",
    "        )\n",
    "\n",
    "        log.debug(\n",
    "            f\"gene_id: {row.gene_id} | dbxref: {row.dbxref} | s: {row.start} | att: {row.attributes}\"\n",
    "        )\n",
    "        log.trace(f\"\\t{check_var = } | {use_NCBI_symbol = } | {use_gene = }\")\n",
    "        log.trace(f\"\\t{row.other_aliases = } | {row.desc = } | {row.gene_symbol = }\")\n",
    "\n",
    "        if check_var in gene_dict:\n",
    "            gene_label = gene_dict[check_var].label\n",
    "            log.debug(\n",
    "                f\"\\t[1st T]Label in gene_dict, L: |{gene_label}| adding: {row.gene_id} #dx {AN}:{row.dbxref} #c {c_text}: {check_desc}\"\n",
    "            )\n",
    "            gene_dict[row.gene_id] = gdt.gene_dict_impl.GeneDbxref(\n",
    "                label=gene_label,\n",
    "                an_source=AN,\n",
    "                dbxref=row.dbxref,\n",
    "                c=f\"{c_text}: {check_desc}\",\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            log.trace(\n",
    "                f\"\\t[1st F]Label not found gene_dict | checking {temp_name} | Label: {check_var}\"\n",
    "            )\n",
    "\n",
    "            if check_var in temp_gene_dict:\n",
    "                gene_label = temp_gene_dict[check_var].label\n",
    "                log.debug(\n",
    "                    f\"\\t[2nd T]Label in {temp_name}, L: |{gene_label}| adding: {row.gene_id} #dx {AN}:{row.dbxref} #c {c_text}: {check_desc}\"\n",
    "                )\n",
    "                temp_gene_dict[row.gene_id] = gdt.gene_dict_impl.GeneDbxref(\n",
    "                    label=gene_label,\n",
    "                    an_source=AN,\n",
    "                    dbxref=row.dbxref,\n",
    "                    c=f\"{c_text}: {check_desc}\",\n",
    "                )\n",
    "            else:\n",
    "\n",
    "                temp_count += 1\n",
    "                label = f\"{organelle_type}-TEMP-{temp_count}\"\n",
    "                log.debug(\n",
    "                    f\"\\t[2nd F]Label not in {temp_name}, new label |{label}| adding: {row.gene_id} #dx {AN}:{row.dbxref} #c {c_text}: {check_desc}\"\n",
    "                )\n",
    "                temp_gene_dict[check_var] = gdt.gene_dict_impl.GeneDescription(\n",
    "                    label=label, source=gn_tag, c=None\n",
    "                )\n",
    "\n",
    "                temp_gene_dict[row.gene_id] = gdt.gene_dict_impl.GeneDbxref(\n",
    "                    label=label,\n",
    "                    an_source=AN,\n",
    "                    dbxref=row.dbxref,\n",
    "                    c=f\"{c_text}: {check_desc}\",\n",
    "                )\n",
    "\n",
    "    return gene_dict, temp_gene_dict, temp_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abbc353",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822b5b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines all the global variables used in the script.\n",
    "# Change these variables to match your local setup.\n",
    "# The most_recent_gdt_file variable should be set to the path of the most recent GDT file,\n",
    "# OR the stripped GDT file used in filter command, if applicable.\n",
    "\n",
    "DATA_DIR = \"/home/brenodupin/matheus/gdt/sandbox/fungi_mt_model2\"\n",
    "most_recent_gdt_filename = \"fungi_mt_model_pilot_01.gdt\"\n",
    "global_query_string = gdt.gff3_utils.QS_GENE_TRNA_RRNA\n",
    "remove_orfs = True\n",
    "organelle_type = \"MT\"\n",
    "gff_suffix = \".gff3\"\n",
    "\n",
    "\n",
    "Entrez.email = \"dupin@alunos.utfpr.edu.br\"\n",
    "Entrez.api_key = \"b3abc1ac7ae9ac035af84ec1abf895878d09\"\n",
    "print(f\"Chosen feature query string: '{global_query_string}'\\n\")\n",
    "\n",
    "# just checking\n",
    "DATA_DIR = Path(DATA_DIR).resolve()\n",
    "if not DATA_DIR.is_dir():\n",
    "    raise FileNotFoundError(f\"Path {DATA_DIR} is not a directory.\")\n",
    "\n",
    "MISC_DIR = DATA_DIR / \"misc\"\n",
    "GDT_DIR = MISC_DIR / \"gdt\"\n",
    "GDT_DIR.mkdir(511, True, True)  # 511 = 0o777\n",
    "\n",
    "AN_missing_gene_dict = MISC_DIR / \"AN_missing_gene_dict.txt\"\n",
    "\n",
    "if not AN_missing_gene_dict.is_file():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Missing {AN_missing_gene_dict}, did you run geneDict filter?\"\n",
    "    )\n",
    "\n",
    "if \"most_recent_gdt_filename\" in globals():\n",
    "    gdt_path = GDT_DIR / most_recent_gdt_filename\n",
    "    if not gdt_path.is_file():\n",
    "        print(\n",
    "            f\"Not found {gdt_path.name}, does it exist in misc/gdt?\\nGDTs in {GDT_DIR}:\"\n",
    "        )\n",
    "        [print(f\" - {f.name}\") for f in sorted(GDT_DIR.glob(\"*.gdt\"))]\n",
    "        raise FileNotFoundError(\n",
    "            f\"Most recent GDT file {gdt_path.name} does not exist in {GDT_DIR}.\"\n",
    "        )\n",
    "else:\n",
    "    print(\n",
    "        \"Warning: 'most_recent_gdt_filename' variable not set.\\n\\n\"\n",
    "        \"If you have a previous GDT file:\\n\"\n",
    "        \"• Set the most_recent_gdt_filename variable\\n\"\n",
    "        \"• Re-run this cell\\n\\n\"\n",
    "        \"If you intend to run this without a GDT file, this warning can be ignored.\"\n",
    "    )\n",
    "    # to simplify the code, a exetution without most_recent_gdt_filename\n",
    "    # basically the same as with one, but with and empty gdt file\n",
    "    gdt_path = GDT_DIR / \"pilot_00.gdt\"\n",
    "    gdt.gene_dict_impl.create_empty_gdt(gdt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61084bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = MISC_DIR / \"01_missing_gene_dict.log\"\n",
    "\n",
    "_, log = gdt.logger_setup.logger_creater(\n",
    "    log_file=log_file, console_level=\"DEBUG\", file_level=\"TRACE\"\n",
    ")\n",
    "log.debug(\"Running from notebook AN_missing_gene_dict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f30404",
   "metadata": {},
   "source": [
    "### TEMP using gff 'gene=' + NCBI description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64970dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(AN_missing_gene_dict, \"r\") as f:\n",
    "    ANs = [line.strip() for line in f.readlines() if line.strip()]\n",
    "print(f\"{len(ANs) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3ad533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GDT file (even if empty)\n",
    "gene_dict = gdt.gene_dict_impl.create_gene_dict(gdt_path, max_an_sources=0)\n",
    "log.info(f\"Loaded gene_dict from {gdt_path}\")\n",
    "log.info(\"Header:\")\n",
    "[log.info(f\"\\t{x}\") for x in gene_dict[\"gdt_header\"]]\n",
    "log.info(\"GDT Info:\")\n",
    "[log.info(f\"\\t{x}\") for x in gene_dict[\"gdt_info\"]]\n",
    "\n",
    "temp_gene_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_gene_dict = {}\n",
    "temp_count = 0\n",
    "errors = []\n",
    "\n",
    "log.info(\" ---- [Starting TEMP process] ----\")\n",
    "for i, AN in enumerate(ANs):\n",
    "    log.debug(f\"-- [Processing: {AN}] --\")\n",
    "\n",
    "    an_path = DATA_DIR / f\"{AN}{gff_suffix}\"\n",
    "    if not an_path.exists():\n",
    "        log.error(f\"Error: {AN} does not exist (an_path: {an_path})\")\n",
    "        errors.append((AN, \"File not found\"))\n",
    "        continue\n",
    "\n",
    "    df = gdt.gff3_utils.load_gff3(an_path, query_string=global_query_string)\n",
    "    df = gdt.gff3_utils.filter_orfs(df) if remove_orfs else df\n",
    "\n",
    "    # getting the gene_id and if it is in the gene_dict\n",
    "    df[\"gene_id\"] = df[\"attributes\"].str.extract(RE_ID, expand=False)\n",
    "    df[\"gene\"] = df[\"attributes\"].str.extract(RE_gene, expand=False)\n",
    "    df[\"in_gene_dict\"] = df[\"gene_id\"].isin(gene_dict)\n",
    "    df[\"has_gene\"] = df[\"gene\"].notna()\n",
    "\n",
    "    # two step method to extract dbxref, first try to get the full dbxref,\n",
    "    # if not all genes are numeric and not NaN, fallback to GeneID,\n",
    "    # check again if all genes are numeric and not NaN.\n",
    "    # if not, raise an error\n",
    "    df[\"dbxref\"] = df[\"attributes\"].str.extract(RE_dbxref, expand=False)\n",
    "\n",
    "    df_missing = df[~df[\"in_gene_dict\"] & ~df[\"has_gene\"]].copy()\n",
    "    df_gene = df[~df[\"in_gene_dict\"] & df[\"has_gene\"]].copy()\n",
    "\n",
    "    # process of 'gene='\n",
    "    if not df_gene.empty:\n",
    "        log.debug(\n",
    "            f\"Found {len(df_gene)} feature(s) with gene= in {AN}, not in gene_dict.\"\n",
    "        )\n",
    "        df_gene[[\"other_aliases\", \"desc\", \"gene_symbol\"]] = [\n",
    "            \"no_other_aliases\",\n",
    "            \"no_description\",\n",
    "            \"no_gene_symbol\",\n",
    "        ]\n",
    "        gene_dict, temp_gene_dict, temp_count = data_process(\n",
    "            df_gene,\n",
    "            AN,\n",
    "            gene_dict,\n",
    "            temp_gene_dict,\n",
    "            organelle_type,\n",
    "            temp_count,\n",
    "            log,\n",
    "            use_gene=True,\n",
    "            temp_name=\"temp_gene\",\n",
    "            c_text=\"gff_gene\",\n",
    "            gn_tag=\"gff_gene\",\n",
    "        )\n",
    "\n",
    "    if df_missing.empty:\n",
    "        log.debug(\n",
    "            \"All features are either in gene_dict or have a gene= attribute. Skipping.\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # search NCBI\n",
    "    with Entrez.esummary(\n",
    "        db=\"gene\", id=\",\".join(df_missing[\"dbxref\"].unique())\n",
    "    ) as search_handle:\n",
    "        try:\n",
    "            search_results = Entrez.read(search_handle)[\"DocumentSummarySet\"][\"DocumentSummary\"]  # type: ignore\n",
    "        except (RuntimeError, KeyError, Exception) as ex:\n",
    "            log.error(f\"{ex} in Entrez.read for {AN}\")\n",
    "            errors.append((AN, \"Entrez.read\"))\n",
    "            continue\n",
    "\n",
    "    if len(search_results) != len(df_missing[\"dbxref\"].unique()):\n",
    "        log.warning(\n",
    "            f\"Number of search results ({len(search_results)}) does not match number of dbxrefs ({len(df_missing['dbxref'].unique())}) for {AN}.\"\n",
    "        )\n",
    "        missing_dbxrefs = set(df_missing[\"dbxref\"].unique()) - set(\n",
    "            x.attributes[\"uid\"] for x in search_results\n",
    "        )\n",
    "        log.warning(f\"Missing dbxrefs: {missing_dbxrefs}\")\n",
    "        log.warning(\"The missing dbxrefs will be under the 'no_description' tag.\")\n",
    "\n",
    "    # format the search results into a DataFrame\n",
    "    temp_df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"dbxref\": x.attributes[\"uid\"],\n",
    "                \"other_aliases\": x.get(\"OtherAliases\", \"no_other_aliases\"),\n",
    "                \"desc\": x.get(\"Description\", \"no_description\"),\n",
    "                \"gene_symbol\": x.get(\"Name\", \"no_gene_symbol\"),\n",
    "            }\n",
    "            for x in search_results\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    df_merged = df_missing.merge(temp_df, on=\"dbxref\", how=\"left\", copy=False)\n",
    "\n",
    "    # in case NCBI did not return any results for some dbxrefs\n",
    "    df_merged[\"other_aliases\"] = df_merged[\"other_aliases\"].fillna(\"no_other_aliases\")\n",
    "    df_merged[\"desc\"] = df_merged[\"desc\"].fillna(\"no_description\")\n",
    "    df_merged[\"gene_symbol\"] = df_merged[\"gene_symbol\"].fillna(\"no_gene_symbol\")\n",
    "\n",
    "    # process of ncbi description\n",
    "    gene_dict, temp_gene_dict, temp_count = data_process(\n",
    "        df_merged, AN, gene_dict, temp_gene_dict, organelle_type, temp_count, log\n",
    "    )\n",
    "\n",
    "\n",
    "log.info(\" ---- [Finished] ----\")\n",
    "if errors:\n",
    "    log.warning(f\"Errors: {len(errors)}\")\n",
    "    for an, msg in errors:\n",
    "        log.warning(f\"  {an} - {msg}\")\n",
    "    log.warning(\n",
    "        \"Entrez.read errors: This is usually a sporadic event or invalid database references.\"\n",
    "    )\n",
    "    log.warning(\"Next steps to diagnose:\")\n",
    "    log.warning(\n",
    "        \"1. Manually verify a few dbxrefs from your GFF file by searching them in NCBI\"\n",
    "    )\n",
    "    log.warning(\"2. If the dbxrefs are valid in NCBI:\")\n",
    "    log.warning(\"   - Save the current gene_dict as your latest GDT file\")\n",
    "    log.warning(\"   - Re-run this section (the issue was likely temporary)\")\n",
    "    log.warning(\"3. If the dbxrefs are invalid/obsolete:\")\n",
    "    log.warning(\"   - Option A: Remove said ANs from your dataset\")\n",
    "    log.warning(\"   - Option B: Manually remove ANs from AN_missing_gene_dict.txt)\")\n",
    "    log.warning(\"     and add those ANs to AN_missing_dbxref.txt instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc2b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if temp_gene_dict:\n",
    "    temp_path = get_most_recent_gdt(GDT_DIR, prefix=\"TEMP_\")\n",
    "    new_path, nth_iteration = increment_gdt_file(temp_path)\n",
    "    log.info(f\"Writing TEMP GDT file: {new_path} | Iteration: {nth_iteration}\")\n",
    "    temp_gene_dict[\"gdt_info\"] = gdt.gene_dict_impl.get_gene_dict_info(temp_gene_dict)\n",
    "    temp_gene_dict[\"gdt_header\"] = [\n",
    "        \"version 0.0.2\",\n",
    "        f\"TEMP - {nth_iteration}\",\n",
    "        f\"{datetime.now().strftime('%Y-%m-%d %H:%M')} - Automatically generated GDT file from AN_missing_gene_dict\",\n",
    "    ]\n",
    "    gdt.gene_dict_impl.write_gdt_file(temp_gene_dict, new_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363af008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving gene_dict with the new data, dont forget to change the most_recent_gdt_filename variable\n",
    "new_path, nth_iteration = increment_gdt_file(gdt_path)\n",
    "log.info(f\"Writing gene_dict file: {new_path} | Iteration: {nth_iteration}\")\n",
    "gene_dict[\"gdt_info\"] = gdt.gene_dict_impl.get_gene_dict_info(gene_dict)\n",
    "gene_dict[\"gdt_header\"].append(\n",
    "    f\"{datetime.now().strftime('%Y-%m-%d %H:%M')} - Data added from TEMP {nth_iteration:02}\"\n",
    ")\n",
    "gdt.gene_dict_impl.write_gdt_file(gene_dict, new_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728db9b1",
   "metadata": {},
   "source": [
    "### TEMP using NCBI Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c69f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANS_Symbol = set()\n",
    "\n",
    "with open(MISC_DIR / \"seed_TEMP_Symbol.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "\n",
    "        if not line or line.startswith(\"#\") or line.startswith(\"[\") or \"#gd\" in line:\n",
    "            continue\n",
    "\n",
    "        ANS_Symbol.add(line.split(\"#dx\", 1)[1].strip().split(\":\", 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4da521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GDT file (even if empty),\n",
    "# if you are running this right after the previous step,\n",
    "# dont forget to change the most_recent_gdt_filename variable\n",
    "# and re-run the setup\n",
    "\n",
    "gene_dict = gdt.gene_dict_impl.create_gene_dict(gdt_path, max_an_sources=0)\n",
    "log.info(f\"Loaded gene_dict from {gdt_path}\\nHeader:\")\n",
    "[log.debug(f\"\\t{x}\") for x in gene_dict[\"gdt_header\"]]\n",
    "log.debug(\"\\nGDT Info:\")\n",
    "[log.debug(f\"\\t{x}\") for x in gene_dict[\"gdt_info\"]]\n",
    "\n",
    "temp_gene_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55886959",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_symbol_gene_dict = {}\n",
    "temp_count = 0\n",
    "errors = []\n",
    "log.info(\" ---- [Starting TEMP process] ----\")\n",
    "for i, AN in enumerate(ANS_Symbol):\n",
    "    log.debug(f\"-- [Processing: {AN}] --\")\n",
    "\n",
    "    an_path = DATA_DIR / f\"{AN}{gff_suffix}\"\n",
    "    if not an_path.exists():\n",
    "        log.error(f\"Error: {AN} does not exist (an_path: {an_path})\")\n",
    "        errors.append((AN, \"File not found\"))\n",
    "        continue\n",
    "\n",
    "    df = gdt.gff3_utils.load_gff3(an_path, query_string=global_query_string)\n",
    "    df = gdt.gff3_utils.filter_orfs(df) if remove_orfs else df\n",
    "\n",
    "    # getting the gene_id and if it is in the gene_dict\n",
    "    df[\"gene_id\"] = df[\"attributes\"].str.extract(RE_ID, expand=False)\n",
    "    df[\"in_gene_dict\"] = df[\"gene_id\"].isin(gene_dict)\n",
    "\n",
    "    # two step method to extract dbxref, first try to get the full dbxref,\n",
    "    # if not all genes are numeric and not NaN, fallback to GeneID,\n",
    "    # check again if all genes are numeric and not NaN.\n",
    "    # if not, raise an error\n",
    "    df[\"dbxref\"] = df[\"attributes\"].str.extract(RE_dbxref, expand=False)\n",
    "\n",
    "    df_missing = df[~df[\"in_gene_dict\"]].copy()\n",
    "    if df_missing.empty:\n",
    "        log.debug(\"All features are in gene_dict. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # search NCBI\n",
    "    with Entrez.esummary(\n",
    "        db=\"gene\", id=\",\".join(df_missing[\"dbxref\"].unique())\n",
    "    ) as search_handle:\n",
    "        try:\n",
    "            search_results = Entrez.read(search_handle)[\"DocumentSummarySet\"][\"DocumentSummary\"]  # type: ignore\n",
    "        except (RuntimeError, KeyError, Exception) as ex:\n",
    "            log.error(f\"{ex} in Entrez.read for {AN}\")\n",
    "            errors.append((AN, \"Entrez.read\"))\n",
    "            continue\n",
    "\n",
    "    if len(search_results) != len(df_missing[\"dbxref\"].unique()):\n",
    "        log.warning(\n",
    "            f\"Number of search results ({len(search_results)}) does not match number of dbxrefs ({len(df_missing['dbxref'].unique())}) for {AN}.\"\n",
    "        )\n",
    "        missing_dbxrefs = set(df_missing[\"dbxref\"].unique()) - set(\n",
    "            x.attributes[\"uid\"] for x in search_results\n",
    "        )\n",
    "        log.warning(f\"Missing dbxrefs: {missing_dbxrefs}\")\n",
    "        log.warning(\"The missing dbxrefs will be under the 'no_description' tag.\")\n",
    "\n",
    "    # format the search results into a DataFrame\n",
    "    temp_df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"dbxref\": x.attributes[\"uid\"],\n",
    "                \"other_aliases\": x.get(\"OtherAliases\", \"no_other_aliases\"),\n",
    "                \"desc\": x.get(\"Description\", \"no_description\"),\n",
    "                \"gene_symbol\": x.get(\"Name\", \"no_gene_symbol\"),\n",
    "            }\n",
    "            for x in search_results\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    df_merged = df_missing.merge(temp_df, on=\"dbxref\", how=\"left\", copy=False)\n",
    "\n",
    "    # in case NCBI did not return any results for some dbxrefs\n",
    "    df_merged[\"other_aliases\"] = df_merged[\"other_aliases\"].fillna(\"no_other_aliases\")\n",
    "    df_merged[\"desc\"] = df_merged[\"desc\"].fillna(\"no_description\")\n",
    "    df_merged[\"gene_symbol\"] = df_merged[\"gene_symbol\"].fillna(\"no_gene_symbol\")\n",
    "\n",
    "    # process of ncbi gene sym,bol\n",
    "    gene_dict, temp_symbol_gene_dict, temp_count = data_process(\n",
    "        df_merged,\n",
    "        AN,\n",
    "        gene_dict,\n",
    "        temp_symbol_gene_dict,\n",
    "        organelle_type,\n",
    "        temp_count,\n",
    "        log,\n",
    "        temp_name=\"temp_symbol\",\n",
    "        use_NCBI_symbol=True,\n",
    "        c_text=\"ncbi_symbol\",\n",
    "    )\n",
    "\n",
    "\n",
    "log.info(\" ---- [Finished] ----\")\n",
    "if errors:\n",
    "    log.warning(f\"Errors: {len(errors)}\")\n",
    "    for an, msg in errors:\n",
    "        log.warning(f\"  {an} - {msg}\")\n",
    "    log.warning(\n",
    "        \"Entrez.read errors: This is usually a sporadic event or invalid database references.\"\n",
    "    )\n",
    "    log.warning(\"Next steps to diagnose:\")\n",
    "    log.warning(\n",
    "        \"1. Manually verify a few dbxrefs from your GFF file by searching them in NCBI\"\n",
    "    )\n",
    "    log.warning(\"2. If the dbxrefs are valid in NCBI:\")\n",
    "    log.warning(\"   - Save the current gene_dict as your latest GDT file\")\n",
    "    log.warning(\"   - Re-run this section (the issue was likely temporary)\")\n",
    "    log.warning(\"3. If the dbxrefs are invalid/obsolete:\")\n",
    "    log.warning(\"   - Option A: Remove said ANs from your dataset\")\n",
    "    log.warning(\"   - Option B: Manually remove ANs from AN_missing_gene_dict.txt)\")\n",
    "    log.warning(\"     and add those ANs to AN_missing_dbxref.txt instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2a7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if temp_symbol_gene_dict:\n",
    "    temp_path = get_most_recent_gdt(GDT_DIR, prefix=\"TEMP_Symbol_\")\n",
    "    new_path, symbol_iteration = increment_gdt_file(temp_path)\n",
    "    log.info(\n",
    "        f\"Writing TEMP Symbol GDT file: {new_path} | Iteration: {symbol_iteration}\"\n",
    "    )\n",
    "    temp_symbol_gene_dict[\"gdt_info\"] = gdt.gene_dict_impl.get_gene_dict_info(\n",
    "        temp_symbol_gene_dict\n",
    "    )\n",
    "    temp_symbol_gene_dict[\"gdt_header\"] = [\n",
    "        \"version 0.0.2\",\n",
    "        f\"TEMP Symbol - {symbol_iteration}\",\n",
    "        \"Automagically generated by AN_missing_gene_dict.ipynb | TEMP Symbol using NCBI gene symbol\",\n",
    "    ]\n",
    "    gdt.gene_dict_impl.write_gdt_file(temp_symbol_gene_dict, new_path, overwrite=True)\n",
    "else:\n",
    "    log.info(\n",
    "        \"No TEMP Symbol GDT file created, meaning no unknown gene symbols were found.\"\n",
    "    )\n",
    "    symbol_iteration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5d9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving gene_dict with the new data, dont forget to change the most_recent_gdt_filename variable\n",
    "new_path, nth_iteration = increment_gdt_file(gdt_path)\n",
    "log.info(f\"Writing gene_dict file: {new_path} | pilot itr: {nth_iteration}\")\n",
    "gene_dict[\"gdt_info\"] = gdt.gene_dict_impl.get_gene_dict_info(gene_dict)\n",
    "gene_dict[\"gdt_header\"].append(\n",
    "    f\"{datetime.now().strftime('%Y-%m-%d %H:%M')} - Data added from TEMP Symbol {symbol_iteration:02d}\"\n",
    ")\n",
    "gdt.gene_dict_impl.write_gdt_file(gene_dict, new_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d69fe05",
   "metadata": {},
   "source": [
    "### Genes Discard using dbxref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b38d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_string = \"discard-\"\n",
    "genes_to_remove = \"genome_features_to_remove.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1c6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_gene_ids = {}\n",
    "with open(MISC_DIR / genes_to_remove, \"r\") as f:\n",
    "    for line in f:\n",
    "        if (\n",
    "            not line.strip()\n",
    "            or line.startswith(\"#\")\n",
    "            or line.startswith(\"[\")\n",
    "            or \"#gd\" in line\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        gene_id, an = line.split(\"#c\", 1)[0].split(\"#dx\", 1)\n",
    "        gene_id = gene_id.strip()\n",
    "        an = an.split(\":\", 1)[0].strip()\n",
    "\n",
    "        if an not in remove_gene_ids:\n",
    "            remove_gene_ids[an] = set([gene_id])\n",
    "        else:\n",
    "            remove_gene_ids[an].add(gene_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17773f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(f\"Removing {len(remove_gene_ids)} gene IDs from GFF files.\")\n",
    "for an in remove_gene_ids.keys():\n",
    "    log.trace(f\"Processing {an} for removal of gene IDs {remove_gene_ids[an]}\")\n",
    "    an_path = DATA_DIR / f\"{an}{gff_suffix}\"\n",
    "    with open(an_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    headers, index = [], 0\n",
    "    while lines[index].startswith(\"#\"):\n",
    "        headers.append(lines[index].strip())\n",
    "        index += 1\n",
    "\n",
    "    pattern = re.compile(\"|\".join([f\"ID={x};\" for x in remove_gene_ids[an]]))\n",
    "    log.trace(f\"Pattern for removal: {pattern.pattern}\")\n",
    "    contents = []\n",
    "\n",
    "    for line in lines[index:]:\n",
    "        if not (line := line.strip()):\n",
    "            continue\n",
    "        line = line.split(\"\\t\")\n",
    "\n",
    "        # line[2] is type line, line[8] is attributes\n",
    "        if pattern.search(line[8]):\n",
    "            if remove_string not in line[2]:\n",
    "                line[2] = remove_string + line[2]\n",
    "\n",
    "        contents.append(\"\\t\".join(line))\n",
    "\n",
    "    with open(an_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(headers))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\".join(contents))\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "log.info(f\"Finished removing gene IDs from {len(remove_gene_ids)} GFF files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
