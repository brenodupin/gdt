{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9664aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "import gdt\n",
    "\n",
    "from Bio import Entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d05f8d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nth_iteration = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fff3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines all the global variables used in the script.\n",
    "# Change these variables to match your local setup.\n",
    "# The most_recent_gdt_file variable should be set to the path of the most recent GDT file,\n",
    "# OR the stripped GDT file used in filter command, if applicable.\n",
    "\n",
    "DATA_DIR = \"../test/Test_group16\"\n",
    "AN_missing_dbxref = \"../test/Test_group16/AN_missing_dbxref\"\n",
    "#most_recent_gdt_file = \"../test/Test_group16/Test_group16.gdt\"\n",
    "remove_orfs = True\n",
    "organelle_type = \"MT\"\n",
    "gff_suffix = \".gff3\"\n",
    "\n",
    "Entrez.email = 'dupin@alunos.utfpr.edu.br'\n",
    "Entrez.api_key = 'b3abc1ac7ae9ac035af84ec1abf895878d09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca23d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recent_gdt_file = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37b27fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you set up a stripped GDT file, please set the path to it in the most_recent_gdt_file variable.\n",
      "Otherwise, ignore this message.\n"
     ]
    }
   ],
   "source": [
    "# Check if all variables exist\n",
    "DATA_DIR = Path(DATA_DIR).resolve()\n",
    "AN_missing_dbxref = Path(AN_missing_dbxref).resolve()\n",
    "\n",
    "if not DATA_DIR.exists() and not DATA_DIR.is_dir():\n",
    "    raise FileNotFoundError(f\"Data directory {DATA_DIR} does not exist or is not a directory.\")\n",
    "\n",
    "if not AN_missing_dbxref.exists() and not AN_missing_dbxref.is_file():\n",
    "    raise FileNotFoundError(f\"AN missing dbxref {AN_missing_dbxref} does not exist or is not a file.\")\n",
    "\n",
    "if not most_recent_gdt_file:\n",
    "    if nth_iteration > 1:\n",
    "        raise FileNotFoundError(f\"Most recent GDT file {most_recent_gdt_file} does not exist or is not a file.\")\n",
    "    else:\n",
    "        print(f\"If you set up a stripped GDT file, please set the path to it in the most_recent_gdt_file variable.\")\n",
    "        print(f\"Otherwise, ignore this message.\")\n",
    "else:\n",
    "    most_recent_gdt_file = Path(most_recent_gdt_file).resolve()\n",
    "    if not most_recent_gdt_file.exists() and not most_recent_gdt_file.is_file():\n",
    "        raise FileNotFoundError(f\"Most recent GDT file {most_recent_gdt_file} does not exist or is not a file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ddbed68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 19:21:13,004 - DEBUG - Logger setup complete. Logging to /home/brenodupin/matheus/gdt/test/Test_group16/0_test_3.log\n",
      "2025-05-22 19:21:13,012 - DEBUG - Running from notebook AN_missing_dbxref\n"
     ]
    }
   ],
   "source": [
    "_, logger = gdt.logger_setup.logger_creater(log_file=DATA_DIR / '0_test_3.log', console_level=\"DEBUG\", file_level=\"TRACE\")\n",
    "logger.debug(\"Running from notebook AN_missing_dbxref\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15a53d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ANs): 200\n"
     ]
    }
   ],
   "source": [
    "with open(AN_missing_dbxref, \"r\") as f:\n",
    "    ANs = [line.strip() for line in f.readlines() if line.strip()]\n",
    "print(f\"len(ANs): {len(ANs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba5f282",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dbxref_path = DATA_DIR / \"missing_dbxref\"\n",
    "missing_dbxref_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0f3d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GDT file\n",
    "if most_recent_gdt_file:\n",
    "    gene_dict = gdt.gene_dict.create_gene_dict(most_recent_gdt_file, max_an_sources=0)\n",
    "else:\n",
    "    gene_dict = {}\n",
    "\n",
    "temp_gene_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11fbe452",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "for AN in ANs:\n",
    "    an_path = DATA_DIR / f'{AN}{gff_suffix}'\n",
    "    if not an_path.exists():\n",
    "        logger.error(f'Error: {AN} does not exist (an_path: {an_path})')\n",
    "        continue\n",
    "    \n",
    "    df = gdt.gff3_utils.load_gff3(an_path, query_string=gdt.gff3_utils.QS_GENE_TRNA_RRNA, usecols=['seqid', 'start', 'end', 'type', 'attributes'])\n",
    "    df = gdt.gff3_utils.filter_orfs(df) if remove_orfs else df\n",
    "\n",
    "    df['gene_id'] = df['attributes'].str.split(';').str[0].str.replace('ID=', '', regex=False)\n",
    "    df['in_gene_dict'] = df['gene_id'].isin(gene_dict)\n",
    "    df_missing = df[~df['in_gene_dict']].copy()\n",
    "\n",
    "    temp_list.extend(df_missing[['gene_id', 'seqid']].to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c56ce2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dbxref = (pd.DataFrame(temp_list).groupby('gene_id')['seqid']\n",
    "                .agg(list)\n",
    "                .sort_index())  # Sort by gene_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e36b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write here anything you want to add to the missing_dbxref file, or leave it empty\n",
    "comment = \"manual insertion from missing_dbxref_compiled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d80463db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(missing_dbxref_path / 'compiled.txt', 'w+') as f1:\n",
    "    for gene_id, seqid in agg_dbxref.items():\n",
    "        f1.write(f'{gene_id} #gn {\" \".join(seqid)}{ \" #c \" + comment if comment else \"\" }\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c942a16",
   "metadata": {},
   "source": [
    "After manual parsing of compiled.txt,  \n",
    "create problems.txt, with names that  \n",
    "are not readily indentifiable or that need deeper investigation.\n",
    "\n",
    "The names that are easily identifiable should be added to the most  \n",
    "recent _pilot.gdt, and this gdt should be them loaded above, before  \n",
    "the next part of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d985e87",
   "metadata": {},
   "source": [
    "### Deeper investigation using other gff attributes, primarily 'Name='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2bbf3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_with_no_dbxref = set()\n",
    "with open(missing_dbxref_path / 'problems.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('#') or not line.strip():\n",
    "            continue\n",
    "        # Get ANs part (after '||') and split into individual ANs\n",
    "        if '#c' in line:\n",
    "            line = line.split('#c')[0].strip()\n",
    "        \n",
    "        ans = line.split('#gn')[1].strip().split()\n",
    "        # Add each AN to the set\n",
    "        an_with_no_dbxref.update(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0d6ec37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AP012272.1',\n",
       " 'AP017979.1',\n",
       " 'AP017980.1',\n",
       " 'AP017981.1',\n",
       " 'AP024424.1',\n",
       " 'AP024451.1',\n",
       " 'AP024468.1',\n",
       " 'AY376688.1',\n",
       " 'D31785.1',\n",
       " 'JQ346808.1',\n",
       " 'KC832409.1',\n",
       " 'KY245891.1',\n",
       " 'LC532387.1',\n",
       " 'LC545447.1',\n",
       " 'LC602355.1',\n",
       " 'LC604067.1',\n",
       " 'LC612919.1',\n",
       " 'LK392300.1',\n",
       " 'MH725795.1'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "an_with_no_dbxref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb7d1877",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_NAME = re.compile(r'Name=([^;]*)(?:;|$)')\n",
    "RE_PRODUCT = re.compile(r'product=([^;]*)(?:;|$)')\n",
    "RE_DESCRIPTION = re.compile(r'description=([^;]*)(?:;|$)')\n",
    "RE_GENE = re.compile(r'gene=([^;]*)(?:;|$)')\n",
    "RE_GENE_SYNONYM = re.compile(r'gene_synonym=([^;]*)(?:;|$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "for AN in an_with_no_dbxref:\n",
    "    an_path = DATA_DIR / f'{AN}{gff_suffix}'\n",
    "    df = gdt.gff3_utils.load_gff3(an_path, query_string=gdt.gff3_utils.QS_GENE_TRNA_RRNA, usecols=gdt.GFF3_COLUMNS) # TODO change query_string!\n",
    "    df = gdt.gff3_utils.filter_orfs(df) if remove_orfs else df\n",
    "\n",
    "    df['gene_id'] = df['attributes'].str[3:].str.partition(';', expand=False).str[0]\n",
    "    df = df[~df['gene_id'].isin(gene_dict)]\n",
    "    \n",
    "    df['name'] = df['attributes'].str.extract(RE_NAME, expand=False)\n",
    "    df['product'] = df['attributes'].str.extract(RE_PRODUCT, expand=False)\n",
    "    df['description'] = df['attributes'].str.extract(RE_DESCRIPTION, expand=False)\n",
    "    df['gene'] = df['attributes'].str.extract(RE_GENE, expand=False)\n",
    "    df['gene_synonym'] = df['attributes'].str.extract(RE_GENE_SYNONYM, expand=False)\n",
    "\n",
    "    if df[['name', 'product', 'description', 'gene', 'gene_synonym']].isna().all(axis=1).any():\n",
    "        print(f'Warning: {AN} has a row with no identifiable atribute.')\n",
    "        print('Please modify this script to add a new possible identifiable attribute or just remove the AN from the list.')\n",
    "        print(df[df[['name', 'product', 'description', 'gene', 'gene_synonym']].isna().all(axis=1)])\n",
    "\n",
    "    temp_list.extend(df.to_dict('records'))\n",
    "\n",
    "features_info_df = pd.DataFrame(temp_list)\n",
    "features_info_df = features_info_df.drop(columns=['source', 'type', 'start', 'end', 'score', 'strand', 'phase', 'attributes'])\n",
    "\n",
    "dc = [col for col in ['product', 'description', 'gene', 'gene_synonym'] if features_info_df[col].isna().all()]\n",
    "\n",
    "features_info_df['feature_name'] = (features_info_df['gene']\n",
    "                                     .fillna(features_info_df['product'])\n",
    "                                     .fillna(features_info_df['description'])\n",
    "                                     .fillna(features_info_df['name'])\n",
    "                                     .fillna(features_info_df['gene_synonym']))\n",
    "\n",
    "features_info_df = features_info_df.drop(columns=dc)\n",
    "\n",
    "\n",
    "features_info_df = features_info_df.sort_values(by='feature_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c191a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_gdt_compliance = True\n",
    "comment = 'Manual from missing_dbxref_names_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dbc0aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_dict = {'12S RNA', '12S ribosomal RNA', '15S rRNA', '16S RNA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3ed357",
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_gdt_compliance:\n",
    "    gdt_str = f' #gd MANUAL{ \" #c \" + comment if comment else \"\" }'\n",
    "else:\n",
    "    gdt_str = \"\"\n",
    "\n",
    "# df with 2 columns, one for feature_names and one for in_gene_dict\n",
    "new_df = pd.DataFrame({'feature_name': features_info_df['feature_name'].unique()})\n",
    "new_df['in_gene_dict'] = new_df['feature_name'].isin(gene_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5320d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_names = features_info_df['name'].dropna().unique()\n",
    "with open(missing_dbxref_path / 'feature_name.txt', 'w+') as f1:\n",
    "    for name in new_df[~new_df['in_gene_dict']]['feature_name']:\n",
    "        f1.write(f'{name}{gdt_str}\\n')\n",
    "\n",
    "features_info_df.to_csv(missing_dbxref_path / 'features_info.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d13888a",
   "metadata": {},
   "source": [
    "The user must now parse feature_names.txt  \n",
    "\n",
    "Features that can be easily identifiable must be added to the current  \n",
    "version of the gdt, and features that needs a more deep investigation should be  \n",
    "copied to a new file name 'feature_unk.txt'\n",
    "  \n",
    "The program will now try to automatically add the gene_ids with feature name  \n",
    "that __is not__ in 'feature_unk.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6dd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the names exist in the gene_dict\n",
    "features_info_df = pd.read_csv(missing_dbxref_path / 'features_info.tsv', sep='\\t')\n",
    "\n",
    "names_unk = set()\n",
    "with open(missing_dbxref_path / 'feature_unk.txt', 'r') as f1:\n",
    "    for line in f1:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        if '#gd' in line:\n",
    "            line = line.split('#gd')[0].strip()\n",
    "        \n",
    "        names_unk.add(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef05f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_not_in_dict = set()\n",
    "all_names = set(features_info_df['feature_name'].unique()) - names_unk\n",
    "for name in all_names:\n",
    "    if name not in gene_dict:\n",
    "        names_not_in_dict.add(name)\n",
    "\n",
    "if names_not_in_dict:\n",
    "    print(f'Warning: {len(names_not_in_dict)} names not in gene_dict!')\n",
    "    print(f'These names are not in feature_unk, so you marked them as identifiable. Please identify them or add them feature_unk.')\n",
    "    [print(name) for name in names_not_in_dict]\n",
    "    raise ValueError(f'Error: {len(names_not_in_dict)} names not in gene_dict!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad26831",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \"automated insertion from missing_dbxref_names_clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e914f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in features_info_df[~features_info_df['feature_name'].isin(names_unk)].itertuples():\n",
    "    # sanity check\n",
    "    if r.feature_name not in gene_dict:\n",
    "        raise ValueError(f'Error: {r.feature_name} not in gene_dict! how? did you run the step above without error?')\n",
    "\n",
    "    gene_dict[gene_id] = gdt.gene_dict.GeneGeneric(\n",
    "                label=gene_dict[r.feature_name].label,\n",
    "                an_sources=r.seqid,\n",
    "                c=comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82329a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO save new version of gene_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a1d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_dbxref_names_unk.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9262ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df_rows(cds_trna):\n",
    "    for row_cds in cds_trna.itertuples():\n",
    "        print(f'\\ts: {row_cds.start}| e: {row_cds.end} | {row_cds.attributes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeb51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the names exist in the gene_dict\n",
    "names_unk = set()\n",
    "with open(missing_dbxref_path / 'missing_dbxref_names_unk.txt', 'r') as f1:\n",
    "    for line in f1:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        if '#gd' in line:\n",
    "            line = line.split('#gd')[0].strip()\n",
    "        \n",
    "        names_unk.add(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eea968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names_unk  = pd.read_csv(missing_dbxref_path / 'missing_dbxref_names_raw.tsv', sep='\\t')\n",
    "df_names_unk = df_names_unk[df_names_unk['name'].isin(names_unk)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c24e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_an_gene = {}\n",
    "for an in an_set:\n",
    "    for gene_id, seqid in temp_gene_an.items():\n",
    "        if an in seqid:\n",
    "            if an not in dict_an_gene:\n",
    "                dict_an_gene[an] = []\n",
    "            dict_an_gene[an].append(gene_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d637aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_an_gene\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
